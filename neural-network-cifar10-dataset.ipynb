{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11275484,"sourceType":"datasetVersion","datasetId":7048991}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Neural Network on Cifar Datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Hello everyone and Professor Di Bo Ya. My name is Denzel Elden Wijaya, and in this notebook, I will demonstrate how to implement a Neural Network using the CIFAR dataset. Instead of using a built-in dataset loader, I will extract the raw data and create a custom dataset class that inherits from `torch.utils.data.Dataset`. This custom dataset will then be passed to `torch.utils.data.DataLoader` to enable efficient data loading during training.","metadata":{}},{"cell_type":"markdown","source":"The process will include these steps:\n1. Load and Prepare the Dataset\n2. Build the initial Neural Network Model\n3. Tune the Model\n4. Conclusion","metadata":{}},{"cell_type":"markdown","source":"## 1. Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass CifarDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_to_idx = {}\n\n        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n            class_path = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_path):\n                self.class_to_idx[class_name] = idx\n                for file_name in os.listdir(class_path):\n                    if file_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                        self.image_paths.append(os.path.join(class_path, file_name))\n                        self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        label = self.labels[index]\n        image = Image.open(image_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:23:48.748084Z","iopub.execute_input":"2025-04-05T04:23:48.748278Z","iopub.status.idle":"2025-04-05T04:23:56.759601Z","shell.execute_reply.started":"2025-04-05T04:23:48.748259Z","shell.execute_reply":"2025-04-05T04:23:56.758687Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar10-dataset/cifar10_train\", transform=transform)\ntest_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar10-dataset/cifar10_test\", transform=transform)\n\ncifar_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ncifar_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\nprint(f\"Total Training Data: {len(train_dataset)}\")\nprint(f\"Total Testing Data: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:00.431895Z","iopub.execute_input":"2025-04-05T04:24:00.432162Z","iopub.status.idle":"2025-04-05T04:24:01.503946Z","shell.execute_reply.started":"2025-04-05T04:24:00.432139Z","shell.execute_reply":"2025-04-05T04:24:01.503175Z"}},"outputs":[{"name":"stdout","text":"Total Training Data: 50000\nTotal Testing Data: 10000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# let's check the first image and its label\n\nfrom IPython.display import display\n\nimage, label = train_dataset[0]\nimage = transforms.ToPILImage()(image)\ndisplay(image)\n\nclass_names = list(train_dataset.class_to_idx.keys())\nlabel_name = class_names[label]\n\nprint(f\"Label: {label_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:04.291809Z","iopub.execute_input":"2025-04-05T04:24:04.292106Z","iopub.status.idle":"2025-04-05T04:24:04.427988Z","shell.execute_reply.started":"2025-04-05T04:24:04.292080Z","shell.execute_reply":"2025-04-05T04:24:04.427161Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAILElEQVR4AT1Wy24kSRWNd0Rm1ssuu+1+93Sr6RkQCzQb9rDhA/gLNqzZIbHkL5BmMxK/wA+gEaKFkKan1T3j9qPsKldVvuPJiWqJcslOR2bee+Lcc88N+vs//nkcXYyEUW+090ERYThnjCX8hBgFSwXznrgxFZTSFENw1rsQgq0MZdEvK2GHdtfGq9t9TIxQ3g7WBTKdzJ2zYn1zExFFqOD7UNBhoKIojOKFJPtd03ZjYTSZGirSrt46a4PtZqXmjNihb+zIOe8LyQnpLLm5vjLlNPjY7PYkpakkZydLMbRrQJJSjX0rYrHd9LxQPIUHCzM2g+CF7xHG65Izb0PfsWQrJQUnWoim9UVZGSVIIpGDAEaJM4rxqWQpStr39Y0o1EhIVIoezwolmBJVdTTliZLh/tnrJ5FX2AcYMwXlTJwu59EPWlM3dpUx0+kcIblg1jmuxcuXj2OKfdemgB3SSIL3VnDaaS1DtHbwwhgSie3drDo2VfHzr14fnz/nXFtrnW+1rMDtux/+u75f7Zttv93dre4fnBwzQXyMs/lca7bdbhlPXJvgnKK0rLR4/uR8PjsCuberleC81ATh6vWtPJpffLpygYbEPnz4oJR89er1x48X16uLpt009f76coXSc56admdMySgfx9GHJJWWamJSDe10/Zb+5a9/ShEloaARIqGEhLydrJL8L2U7oN1u54uFFHK/3xeFFhJPkb53CBqiG20P9iCTcQQhrNt2Sjpqdz/WGmQLBoUSxjhlTDDO8SqS0KlBiCxVQk5PZyQ9gtJC8M8ezRELizEBEiMpI8p/IxYovtALs1z3H//5/v7xk2dvni+Fd57hKUSO+QvIhOK9hOgh5GSMIRcukpS4g0t/eAa5EzaNXzk2RBPRIniRGU19XV+O6ssHebfCx8AhY+SPKXhAiwgt0F05E8IlRpEWCZCKU4pvIjQAM7aXSEhAckgPeEQAIim77fvmaj8sClSZONQVd/A0Vdg74ERwhQ+A5/CIi6bGRf7k2J8RZzpIALeBEEg6oRQ05F+GeLH5YTWMceRGhBRGoSWPPrAELPkDyQP+gRlkQI5MeIafr3DtkQcL0DkWQsRKAFEphZB4JFTWjR0uLscFZVwz7ywiJ2w9Q/4MMD+by56h59jYE+KiKpwecufQufZoI5pZojQKLHDlNZeCqP1mWw3Xo5miv7UOFL2LxkgBCTmXLCYfUPVgXVQS7yFYZgxEgNz8H36wGwoQkA4oRZosCI/yCn2SXOq/v5Dy+n7yaCGZniCcACMRu0TVsh4iogshObISwOOg3Hts6PD5TFRKdgzDEOp9j60bY4D8+HT55uWX/u2/V8pt/JOpODk90Z5INJ6wbmSEZzGDRkKFRHQBQJlacJwJzgUAixyGJRT0BvGpKolyMIWpymq+OHrx4tXR7MHapepnf+gbdnrUzXVsx5WzTvR9J5kED0KAJ0F4jqKVLMsKrwuIQFZKGSGZKY2E3VCuhOJoWbCF10ARBQd8SEQ8fSHF6+XH9+/Gf9zWtjRJSy1yEo36gROuy/nJ+dPjk0fKzKHqGBhsfBh6jCEbx7PlObYXDlWC+YXoYT52hJN6uMtkNt3ud4h2t7opDFAxybPuRTWdCo4OEYj+8s0vnjx7Ndi4r/1PP146G6tJOdoaINFkg+1QKQmi0Hvocqg8eIRA+GHomma7Wl127S4Gh4kkQDk6F6PMlCVafTJZemJu7ur50nXDsNtvfNrOlwvOfTEBAg6PtMOAkFVV6UL50fV161Jy3o9DX+83t+2+re8xc0qj0H+Ya7AF5IZVxMl08earX9ok7tb3d3crwOqajkX4PCauc6GDWzEyKU0J6mMYLz9crO9u725vYexw0WxTgsbocQlPbJveOyCJWcnQMi5A56erGyaVHcaxa9EI4zCAhO362ns/DC0MeTE/+c1vfyeN+s+/vvv2m7+pXHMUnGpjMD+RH57mUB9sKqJ5oT7KJJHogvq+2W6ay59uIKOqmqKL23qL+ZynGMC3fVe3bdednj36+ldfF5PJ9cWnt9+9ffb84YOHS2gj+BGtbjhhAjJxRqK+s0T8/808yw13QsLJow7jsL7bZBuA6WHJhnq3H5oG02dzd/P3b7/Bdj++e0+i223vuYinp8tqMoF2T+alKSqGUYCjjlwgHrqTJugwCFMIDK9kIwhsdpv17dXx8ggNAXSTqVoez+CGIDRX/v4qRf/44eyLp7/G6QjOIkFB9iOPbkXbC9LjPMDVHNvJoeEhHP1YGrxvjAqFmU3o+dkZFIknYB4oIDaYQR0cCYcV0I2BgHj4wFcwx9AELvl8jCGKjD1LA9Y8DDDTlN1HKKXhnZ/dP3iGpvFuREqsoHuBETnwhTcDLaiDr3kScEhBJkwjvCCSR8cSCgtYQzAWowsWyCjUiOkioCb0UR54FPLN4wp7BV1KcYOZBOzwaSxjEOGxRIEdbOQhh3mBRaUY2EXdUsDhE48cfDN7Z56SoGLwDkAgK0RBJhIjupCzPO5w/MDRKeMEIJAGwSM/CZm1LHH0akANsh/BEkOKdEqAi2mZONrL+gTtHjScw0atGIbEYYxBxlgAK3gASFgELuwUh8eY4D2w6IPGbC4InJZx1AOpIyng+wfbzD7fdeNgYf4AxwkaSmW2aR6XFKUL6FvMaaokpGDHAd6dZ2V0oNvoAvZHiZQ4guLYKVQkvm1HSmVKPQLkPiPoMugzCpy/UHAQx4iyJGJHuIZG+EylyCFX3MVzSA/7xC0c8UDwwSEwNjyQgj/sE/6qwfJh4uJ8RxI3BgUS/wMsd06K5pJoIwAAAABJRU5ErkJggg==\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDFGlagpBy7dzsYf1rRXSoxGPMu7tXdcsBDkKfY5rSVQuOv4VMu3OMmsvbSI9nE5WS2u4psJaXUigff3Yz+FZ8+mSpP5jR3A+b5Qwzkmu8XdJKIkV2c9AEJrM1OG6j1i2ikhkRIizsxXAyBjr+NJVZXHyKxsWF5pVlEZJisjlcbXU/Kf61bsPFGmS6hHai6WKQgnc6KqDjvxWW1pBcctHHkdzzU4062VAGgjYe6g01OytYXLckk8fw3E0sVn5rhGKbwRyQcZAHas+81S41CQSTwTSEZ2krwtW/sMGRi3RT14UCo3UIhKDjPQUnNt2HypH//2Q==\n"},"metadata":{}},{"name":"stdout","text":"Label: airplane\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# let's check the first 10 images and their labels\n\ndata_iter = iter(cifar_train_loader)\nimages, labels = next(data_iter)\nfor i in range(10):\n    image = transforms.ToPILImage()(images[i])\n    display(image)\n    label_name = class_names[labels[i]]\n    print(f\"Label: {label_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:07.929594Z","iopub.execute_input":"2025-04-05T04:24:07.929885Z","iopub.status.idle":"2025-04-05T04:24:08.490634Z","shell.execute_reply.started":"2025-04-05T04:24:07.929860Z","shell.execute_reply":"2025-04-05T04:24:08.489823Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1Se7juRwRg1kXbRxHlgB6k4rPsGm2ncx496898V6V4l1K/WWeWOODPyxpLnj0A9fU1hG6NJNNHdX2oRpZtNbFbhgcbUYcmpYy0sIkMbxE/wAL9RXKWem3WiRGa4ZDcMDJHlMhWAyoI7jNdZbFxZxGdsysoZ/qeTVXd9TMh+2eVCGOBk4NQ/akmumZmXcF+UFfuf8A6zVie4s0uYw9pIFGednAz3Bqh9tjtLiSab7LMm/ayiM7gp6ZPrWcufozTTsQadLbarqJl1DUo0xgiEHDEnkc9hXUS2kE7rh8L0yprkIbC1lvjILJUQOdpiY8A9q3o2uLV2lPlMD0CjBA9MUkrvcW3Q//2Q==\n"},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDk28xeT/OnLKQCCTmuh8PaBDLqentNMtwJDueJRwFxnBNWpvDOnm+l3XMyoZ3TCR52AEc47jk/lXc8VBOxxLB1WtDkzIx9ajaQ+tdEvhaYxly7jkBRtPP4YqtdeF7y2hZ3VozuC4k4z71P1mm3ZDeCqqLk+nmVLPxnrdqqRR3CeWvyqrRg4HpWxa+PtbE334+u3ATJrg9x3596mjkdTuXd17VzyimbxqSWh6Hf/Ei9aEIkrhx95TgD+VchqPinVL258w3HlkdPL6j8TWOyysSdjk/7ppBb3DdLeY/SM0lFIcpykf/Z\n"},"metadata":{}},{"name":"stdout","text":"Label: ship\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIoUlEQVR4AU1WWXIjxxWsrqqu3hcsJEGCHFEjOeSwv30Rn8A38D18An/7BgofweEIhyNk6ctjzUicGXI4JECAQKPX6q7F2aA+1FgC6CXfli/fc779658dxyG/OiyxOGOtVUq1TauHQfWqa1shBOcc38YYN/TDOKIOxc14EYfYX379AoS/hFhtLdfaUorLI+h40VrqjNBd0/adHPoeZ4TrpmFgtFFS7g9F3w9UeCIIsjyPoohQZzTwC/ILBvBGEwYGXmAp4MePQ4yG845SLiGDGtqiyPJsNsujOIbvsu+bpsajvbR10zWHqmu7dJIjrmPMlgDh6PyLu/jH4TPOasv6zg7aGQbd1Huf08hlTdP+fHNzenYWpaHqOwSIZ+FUFCd+7AsvspTvDof9cxWFgRdwJpAKAzQcuHP8EGeMQBvddF0nkTLk2BfxVDYlHUyUTb765ncItKqqQHhqwI9mfnbuRRNljRDEODx33afH1e3H2yQNFpdnjPGXeo42kDljOSWUMpNEbhJRY6gmDuOxd5K71CmLfTtolKTtW4mCyEETZvzIBIlgqKnuZY+QprOkRSrLkjxQhOu6DKEe8REAIiAOBehYJ2IpMcgYVecXS1f4fB10g/KF6wlX9QMSBD4wTxTFllEGnMDlnmBd0aqurg7Var1lTFxcLIxVSAwOSsiYovE3sEEfROMY5A4+gDOuK07PzpM44szppYSltimlbJqubhqQgbk+l7JtdxtZ7quivF8/g1zTeS6EeyTuWBBuUWBAWjEao4YYwzUhsvVDFs1yMp91sqXUMk601hz+NjL1eBqAtTbxucijJPTm03z6uPOiFeztit1icWq1RmKQDo50GQAQxqlrVFs/P83isN2tmvI5nsxEGLV9RZEZ4Vtl03RKqFcfCgQ9qK7qieCsaAdF2GK57Jl4eHi4//DpJE6XJ3NkHzwamwTolriDMvvdzqoujV1rOmsHvLmgSZqkWe77kTJkV9YiTPP5KXNFkKR+NiNhJql36HrLnDSNp9NZW8sfvvth6Dru2KrYUWRHSvX09Hx3dw8DTHDDHdQuiiPP99FzgnuMMBAObfy0fuiHNoqDJEsRc1F3u0oqhxM84Ad4NW2bTqaV7G/u7xqr9kPHDbKEh3uphiYNvH4YDlV9cZFPpnlvKMiHUhroiSGMmDxOXe73mna9KsvqUFbgh+d5lHGtCGduJ+umVW1v3r6/X1xdiSgDixwf/OB2YIN1wEVjlEZxEBlEbfyHBtNHxUMfGAcADtqyaaTsXE6TOHaFuxnkdrPu+86YoWrqtkUL0s2+TOOQh+goSlxHBS6EaZhkaeAL3OJJZVEBx3FdTlzXcQZwHIRDu2222yz25/MpeIU0IgjobG2Ny1k+zTdF048KymrZxaHHz1JvX1Qh0ZAxRDAI5gQhY6xqOz9CZOgB4ocQTfjBZa/LulmtVpNJfrE8Wz0+ouOQAylT4QVdLz+sV9oYxpzZJM2SEATiHx/uwehDVex3m9NJ4uLikfYaAkKpGfrAha4JcIxzV6FrjAGrCKPo73w6GROJjG53h7pw/YC5URAmnMosCnw+Nhk1rmChXw9tJRs/DqVSd/efm1ZqY1FGhEIZ7fseo6ZXfVmVkOswDHB2s95AV4qyWm23W5S77X9+f9cPTpLmQeglaYwWQCnHEQWPX72+Rn0eNjsMrUHby2tLte4GaUNPaYWZ5jDIB9rLICVjshhv6/YZvD4Ufpg0/fD2/cfy0HD0PLPX18vT85mFLoyd7IzqA98Xl5cf3t4cDqUnvEEOQgIfWfXhSIeqQXiFZ6yuygNmk9HqebeBirS9LD/ef/68evj8KNsmCvjvf/v166sFZHtk4lHsIK0jLSezuf2KvnvzY1l3q/XTiUOlUYk2kSsweoELgtaN3BWHoqzBXAhklmXFrtysn/bbHTUyick3X199/XoJ0oPgCBghw5ByLLQIA8ZmZycXff/dv79/c/Nh03TT2cwrG+O4vu/XVVXXlUNdVBWVeNw8hWFYV119qOB4GnlfXp+cX55MJig7RAvD5nigjaNRZJTG8ORub+z8cvkHLoD2/Fy0EooyMHflhX5TH4gZZrM5czTgpIzlgDC6OGGz2WR5sUizGA6jNwEM4o7wY4YIn0QhdbQXeOn8VDOv2BfqfHGoqn/88193n243243SVg9gQHd6khspoySxul2cZPOTufDQBOYFzViowAg+Qo/gL0FY5+9/+eMk8tMkZiLQzIdxSrQfJxCx7aHiXvjp7vHN92/gfpoE6SSenE6gfwLVxLQl+lhJzJPj6nK08GsDKAQvqmIYFaoR3MUbrCr3e9zPPUjmLPHC6dXy9cns9sPt3cfbzAt8Q3yXS/AIg2/kx4hqqEFFwZvjMc4vGD7SyPJ0uQTDlTFt23X7fch54HtaqWq33W2e6DjmKPX4sC9/s5xdXl3s63p1/+QIlwVePMtQOqRDK8ggiDLiA/rlG8YN0dwGvkVWMHHCmKaqqfv//PfddrX2OTvJc6w/0yxKOcUOB0l9XN17cbbflUkQLGfzxfk5Dz03DFeP208P98pqdD5iAkfHyEA4bHYwj4Yb55ohYZJst+t37+6xr0HmKkmzLDRRSmjSmxr7gOk7VpGnaieH+pWak/3G05HvsuurRRL4++cdFAUSezgchmF4en7eVTV6G5sP6AUBYNhzfvrfj7ppcXcY+menU8oIopfW3da9H/LpfIJ1NX91Fjj2bv+4rdaJ7xuplbQQjPPrL+aniyDPDEdXDbcfPv785j0iGAcLDGA/QrtaTr745hXWgskky/K0KHZ1XTNh5me5F3Ef+q55OIkx0DEGNVEHjAThGCJv725ubn5k2Lmn87Orq1dffnGazbpZ6Xz7tz+NzBxZO1YfuynWP88TILTGGLSYaFo2HbQliDBw0EcoJe4/8nwMHVwi1FhIrunkeg1pLfBcHOeeEB6n/wcPcHY8fyWQBgAAAABJRU5ErkJggg==\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDZ2TOwSMLk8DJqqbK8jnm82388A/Lgnjj1zVhJZBqaQnhV54610zhvJwitIwGAx5/SvJum7HftqcvJGLW3aVJfujLIzHH60Wd3FfW4mhbIyQfYjqK1LmN3R/IiYIQcsfUdQK5i1u/sviN7VIiI5lJKkdDjrimJ2ZpXmn3kEyX1rBI2GUSKo6gHtWpa+J7IWwHnp5rEjyycGsnUZ7uzss2KSyzZCrGCcfU+lVI/t12sY1C2XzVII4H8+tZRdtS9GtzQm1++aGS3tbRyckZ7Envmqem6bPFIbq+dXuSMDb0UVo2TbRILyOUDJ2eVg8dqd5ts8TGO9hEqjPlS5jY/mMU/aX0M+V7o/9k=\n"},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCzL9pe8hNohLnOVDgAj1+atooFdQuCGGeO3tWBqUflJBdhSzWzF8DuCMH/ABq3pN1HPPHGJt28F0APXvgV4WqSOiEFUg11NlkHlHPFeVfEVSNTtQDnMR4/GvUJLpHRl4BHBHoa848VPYN4rt01B5UhW3Uho1yQdxPStqb9+5ypNOzOn1PUbmFGWLTppcqNvzLjP4Gufkh1GzvIZIdP2xyAsyLIDtPXK+hrrZI2Hz9RR8siYrNVUnsEZOLuinZX0mpOZEdWZAROOhBHTj1x1riPGVpLf+IJpYpbZUiiQfvJ1jPT0PNd1bI1reGWNRk/eGOtcV8RNMie/wD7YtHV0lIjnjByYpAP5EVthpKVS9jWVprmW/U//9k=\n"},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDekS3uS3lzlW9S3FWIo/JRpWaJuBgK+M/nUA8OskrkeWPLbJOCcd+akaJIGczy+WoIEbMuV9h615HLqdN7Fa61CciZVs3kWLaOWwwc9vpyKkuYwkTIhlAbBJBzg1V1TVLfRrXz55Bcbl+6MozN6gGm6VrEmq2LXqtGuxiNhydo9xW04+7zIrQj1vxMyaTdx6e7wTxBTvbIZ/mHP1x/OuOXxxrMsUivc7pDwrORx9K9RbyJwY3t05GD8oAOOoqlJoOjzhQ9hANvKeXgfyqqeIhBcriQpNbHEeGorfWJJ5tUkeWdHzz83me3+NdXayadpTyOEljix80axjaSe9Qf8IlZxXRksr2aFjhwDgrg9cVtfYYbaARoWlV8ja6jBPpUVq3M9HoO99z/2Q==\n"},"metadata":{}},{"name":"stdout","text":"Label: deer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3Hdj3o3dOB+dc/wCIPE8GgyxRPbyTvIrPiNgNqjuc1yo+MFgc40W+2jqd6Ct0ruyONq0eZ7HpW7jp+tAbB+7n8a5/SPFNtqqQM1tcWhnAMPngYk74BBxn2NbufeiwrnhHiDxVM/iM3FwYP3kGxkERIx+fSsy/ljhjtp301Y7e6QyQsc4kA6nA6VsXmhaXfqqXLB9pB9OlT/YIBBBALrMUCFI1kAO1fSvnpYuMrtt8x6eGzinSpwpygmlv5/gc4PELi2+yrI6xZUiNJHAGOmK6a28a+IQ9mslzNDHdxsbWRwrhwOCSCPyrPu/DlrdbG3xDDBsqpGfyqy2m/LbxmeIxQjCIU+7nkgHtRDFqKvzO48Xm2GrU+SFNR36Ltp0P/9k=\n"},"metadata":{}},{"name":"stdout","text":"Label: automobile\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDoCkk2VjHzdqzLq1l5Vi3mg/drp7K3Ay78E9sYp1xFEgMjqOO5qpK61JR454i00xTfa2iMZJ/eN0H1rBRnuxtgBSH/AJ6nq/8Au/416D4wWG8LwCNpDt3EfwgCuPCR28ZZ3Coo5Y9BWT0NEexHULdn2l9p4AOaztU8Rwx2ckeYxODtCu3B9+Oa8vF7c/KftUpYdCWOarXGoyySmOIma4PDMx4X6n+lVfQRq63d2cOqPeRX088kqlREqYBz2HtWWttJO4mvMEjlIR91fr6mkhhW3YysxlnP3pD/ACHoKJr0RjJJJbhVHJakB//Z\n"},"metadata":{}},{"name":"stdout","text":"Label: dog\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIMUlEQVR4AU1WW29cVxU+e599rnOzPR57PE7HdlxHCaRpgVSAqIQEgld+BBISz7zwA3jityBV4gFEnygKKAWlSWniNq0via/j8Yzndubc9uXwrTOk6tbIPmdf1vr2t7611mG//cOHxhjOmMVYUZiiwH/8uGVZeBUOxxzHBGOZVJxhI7YVtFruKLCrfC3fLYth1pSrWLG0UgJz2IE5LBUF/TEGZzXnNg7iRz6LQgjaqY2BbyD4v48SEflkzOCg1ngge6VvOAB0IVWOBdsWtAm2y0H7CIGRUpMtmC3PKKVoiaDQwAOGLl8X89/cQJfOlNRCyswqyCkOLBxgK4ZmhgNbUXDOQRsMvbkMMYCBzbDy7VPYiV22oCu9WSqE1kYrDR8GOC1mlwM7cLykythCyFwK5uS4Dhkk4NiAvwvriwdaAMW4uSIEcEB0GEtg1nEcvPCCY5YWMF3SR6A58y1LwrRD3NJqea50QJRiCc8YAFa6gHsCZtscP8MKhI7CiH2lf+BCrMiIVoaBIxwzCkiyLIWcMPcGOmFESDBgAeTkeY5ji2foAGyV/iyhlJQ5NhEKTOFFG4CCbQhHAAkrjGNbqrBsQKEr6CxPjcYzDJJFglMOWBDCEcImWwhcyaEYjSeGWMMcAVkAhNkSPgdfUpH+pLF4oeep1EYxyhXozoZ/kgCpg9hfWMS9oBhYouBKKbjlFjah4WWC4ChlQh7rwsozLLm2x2uB+53tdhKnr84HuXLSPMP+UheLe4AsaBURK2CRFQy+IRiABk5BSLUhxIsMYoi2rDn5RmuNOQ0nCLA5dK2fPNjilriZzeNE/e3Rk/PhDFcuCcMlScrEQDnoUuUS3sCeiOOYmQIxL+yCiDPcd8QP37u/s9XNVXnSylWujLL2dtY7Kv3on8/nKWJWSh5CKU1/Y51MK4WAL/SGcIrQIxKhK0jcFLnOk4KLaSKfH70q0jlYXKpXspw59vrTL6Lj1+cfPT6c5QrMAxaOENEgnZQN1UHViwxCktrkSabiV794/+p6MIuyg1cXw2kMckez5ON/PwFR1WJq5dOt7bvKXVptcKRK4Lq+I8fRlNRlKIxlKEjZULMFd8hkkIzMZzaEzLUS393dvtNtW4wfHp1/9vKgB1WNRmmaaqmSrN9pNeI8XW1VKxX3/r1d4Hvy5eHVcADF4d5USCiWyCkUFhsI6D5GQ6k2F5hHuMVkklcC0e9dukz/8oOHkyi+7PVeHh5ObwaXLwfnSnXCleVamEsW+OJ6OH9nb8t3WbVWcwTyH9kE3XGpVZbpeZwNR5PRNM6yHHewbc1UIc6uzr5+8ey/nz1O4ujXv/md8Ot3395o1szJMVvlu588219LNxxuu76XKaULc7u7FkXDZnM18EOl1XweKW1mUV73vHu3u8iOaB5/9fVXXxwcTSdz3FG8+HL/xdNH8aS/1umeXl7M4pNui7UaYqkS3v/ZzyepbK6sOx6fRROpO5vt1YFt39vbPb+4QtKjcBYqS2PwKQum5rObpUbjvbs79++89ezF+qeffn5wcio4Dxsrrb3dve07D7wgcESKbNe2Y4dWYgXvvv/TsLLieihZvD9Kcmlnmjea60lm+a4f0H6B/FroB5p1HacahI4j2q0P7u1t/enPf2G//+OH8axfpDfX/SFKghDcFoXr2JCccBzojooBNRXmCBd0l6zDuodRCYJ6DaPiB77vuQCLIp/E8Xg8uuxd9AajV2cXgKY9P/z82T9OXx2jhFGBsqTROeSBCrxowrKgqoliR0WHkgbtiNorZ4XnOPCFsgQgqBUSATFUxjNVuJU6lb533r51eXE+2NiEtqLpJEkzKsMS9QYFh54gTeicqjOD3Bcdh7zQD0BYAn+QPS7u+6Hn+bbrBH4lYI5hNlQgOq2V1Xq4dWs9ieejm/5gcNXr9fr9vszhIsUfnM5lnqWpzGJMGqKrvByS1RaeC7YcSmCoHu0Lyca58KoAEseJUVpk0oDNJd6oV+vtdlvJZDi4vrm5QcqfnJxeX18zm0/ns3kUqTSBA1QHgEfNKrsDPeFuKVpKTiUV2SwcL6zbjutY1EQyMZqgtEiqWYVG4USiLzWanc6mbVs7OztoBNxmvd7ZeDJGrxneDAf93vnp2dVVH9kOaSE3qNlRU3KDWj2s1RGfPE9QN0EtmBP7+0+WmxtwC8hhxQ0cJ3QEAohwhoGLKguWOuurSOajk9e9i5Pjw6PhcJjnEiG1XS+sVWvLy9x2ABENC6HOVabQnigykIUQH//9r+329vJyc3Vtba29YQWe50AM+NZDjcwLDVby8XhyfHy8v7//+vXrNE7AC4oNfbWgjhrl+VXueiQAfERBRGVlxTn6dMMNosnkYPoclC0tr9x6q1urVlutJkp0NfTQLqezCPE4OTk+Ozvt9652trc77Q04OD09xXfCeDK5tbnZ3dlFFUUnQm0Aq//65HGaJI1aBaGFWgRQcK7yNL26mE1Hfd8PGo1GvVZF5mQyQ3ihn2Q2JdVKXa81NjdvJQnKWba5ufno0aOHD3+QZ7ilnM+mlap/+/aWECxJkrW1FeT5k/88xYcXPjdIZWAtmc9hCOqfTcdIC1I9N2izZeNHsmlwtdgJEJVKBfpB5G/GIzAWRVNdMBSmpUZ9ealRRQHOZbPZZA++9yOc+fanBxIY1smBVgh2nMToTJgE6m632+m0kZ5juCpHq9VaWVnBp1sURZPpdHtnN5qnvu8j5jBz3b9m737/x+AUSEjS5ZdMKQDkJtouvhJS2MUSiYR6KpUKXJYw4QkRRdJRsaJspgcKqxuEVRjDEcz/Dy4mBTqPoo+rAAAAAElFTkSuQmCC\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCqbrHUinC6DIT2xUF5oV/pkgNzbtJEDl2gO7A/pWz4dj0nVJpYorCeUBWBWSUDn69u9enKpFHGoNmQ96q/xCm/bVYcMKoXMdyZ5DFZTIm44RVJA56ZxVGWWVCQ0bq3o1VzImzOourbXdBvLie00w3KSHdJKZiS3tgduayLfxjqGi3clymgxxysf3gJOCQMcimaX8Qb61cC7VZh/ePBqTW/H7aggghVIAxAZ8AsATyRxxXnyl2OtIcPiPLK7faNBQqxyQs5QUmoeN7bU9Oa1OgWyqBw73Bdk9xgVz72OiNfky6r5qMCSWIOTxjnp3P5VMmnaRJCHj1dIiEOYyM85OBx+FJSG0f/2Q==\n"},"metadata":{}},{"name":"stdout","text":"Label: ship\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDklsJIxjAJ/wBntVqO3mTACyAkcEDNT2boJAGzjr1qxqviUaXE9ra2ALrx5kh+9n29K4KdNSupOx505N2UFcuQafJFa+dMJNuMkdx74pqvZMV25Oe+a5SbxLdXdtJE+VDDG0cAetb+nz2thplnFfyfv5cGMDHyr2ya6oQjF+4YS5l8fUbYXptYAQieYp2lmUHaPb3qr4u1WFvmtI4eXJAAIYjH8Rzya1rvSJBHviGVkJB+uc1h3NgkGpwPcx+YuA21jw2OOfbNKaklZ7GtN8s7mTbu66bcXt1bbUkHlQh+jN1JH0Hf3p+m6XcXbQGadJC20hVzlRnPOfYfrXczeF/7SuLe+vpC0aLtFuDhVHdgK0W0NIEaAlPMRd0LYwHWtY0n2G6t7n//2Q==\n"},"metadata":{}},{"name":"stdout","text":"Label: frog\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDaEucg2yHPcjJpHQTJ5bRQquc8DFSKyorNjgAk4p51jT7O1EtxHHKHGQokxIPfFZpylolcdktWV1sIBhtqAj05z9ae8UAJJiiYn1jFXY7rTr6Ey2RnxnBSeHafz71FIFA5AqeZ31GkjOSUOCjD1BFael2mjSSN/aE/k3OweSSm5iB7kduKo6WqW0SI8C+WvZQAfzqZL8x60+LdY7JAAHuVxjK4455Hv1qVvoRYDrUs8giuGuDjPlmVQSVHHUf1qGe/ggnxLE8hwDtCkjB78VHbtBaF1Sea4UnhQu1R9M80572TBCQogPr8xo0T0RV2f//Z\n"},"metadata":{}},{"name":"stdout","text":"Label: airplane\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Check the shape of the images and labels\n\nprint(f\"Shape of images: {images.shape}\")\nprint(f\"Label batch: {labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:08.491871Z","iopub.execute_input":"2025-04-05T04:24:08.492164Z","iopub.status.idle":"2025-04-05T04:24:08.501138Z","shell.execute_reply.started":"2025-04-05T04:24:08.492133Z","shell.execute_reply":"2025-04-05T04:24:08.500417Z"}},"outputs":[{"name":"stdout","text":"Shape of images: torch.Size([64, 3, 32, 32])\nLabel batch: tensor([2, 8, 2, 2, 4, 1, 5, 8, 6, 0, 9, 7, 4, 3, 3, 9, 9, 0, 8, 1, 6, 0, 2, 9,\n        2, 5, 7, 3, 5, 9, 2, 1, 4, 6, 5, 2, 2, 2, 6, 1, 0, 4, 9, 2, 9, 8, 2, 4,\n        3, 9, 1, 4, 0, 2, 4, 6, 8, 1, 5, 9, 0, 5, 0, 0])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"We have successfully loaded the CIFAR dataset and implemented a custom dataset class. After ensuring that the dataset is properly processed, we've verified that the images and labels are correctly associated and displayed. The dataset is now ready for training.","metadata":{}},{"cell_type":"markdown","source":"## 2. Build the Initial Neural Network Model","metadata":{}},{"cell_type":"markdown","source":"With the dataset prepared, we will proceed to the second part of this task, which involves contructing the initial versioon of the model. In this phase, we will build a basic neural network architecture, focusing on the key components without applying any advanced optimizations or refinements. This initial model will serve as a baseline for later improvements.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(3 * 32 * 32, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n        \n        self.__initialize_weights__()\n        \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n                    \n                    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n        \nmodel = SimpleNN()\n\nprint(model.fc1.weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:32.882390Z","iopub.execute_input":"2025-04-05T04:24:32.882819Z","iopub.status.idle":"2025-04-05T04:24:32.956528Z","shell.execute_reply.started":"2025-04-05T04:24:32.882779Z","shell.execute_reply":"2025-04-05T04:24:32.955669Z"}},"outputs":[{"name":"stdout","text":"Parameter containing:\ntensor([[-0.0354, -0.0151, -0.0164,  ..., -0.0339,  0.0402, -0.0243],\n        [-0.0170,  0.0270,  0.0283,  ..., -0.0188, -0.0197,  0.0188],\n        [ 0.0014, -0.0318,  0.0388,  ..., -0.0117, -0.0182, -0.0404],\n        ...,\n        [-0.0208,  0.0167, -0.0331,  ...,  0.0048,  0.0351,  0.0234],\n        [-0.0328, -0.0036, -0.0159,  ..., -0.0394,  0.0221,  0.0244],\n        [ 0.0323,  0.0345,  0.0132,  ..., -0.0383, -0.0209, -0.0102]],\n       requires_grad=True)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"device = torch.device('cuda')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\ndef train(model, train_loader, criterion, optimizer, epochs = 5):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            running_loss += loss.item()\n\n        accuracy = 100 * correct / total\n        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {running_loss:.4f} - Accuracy: {accuracy:.2f}%\")\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:24:33.395234Z","iopub.execute_input":"2025-04-05T04:24:33.395520Z","iopub.status.idle":"2025-04-05T04:36:07.876968Z","shell.execute_reply.started":"2025-04-05T04:24:33.395497Z","shell.execute_reply":"2025-04-05T04:36:07.876237Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5] - Loss: 1455.5786 - Accuracy: 33.57%\nEpoch [2/5] - Loss: 1294.4436 - Accuracy: 40.94%\nEpoch [3/5] - Loss: 1234.6952 - Accuracy: 43.39%\nEpoch [4/5] - Loss: 1186.1363 - Accuracy: 45.82%\nEpoch [5/5] - Loss: 1159.7326 - Accuracy: 47.09%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def evaluate(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:36:07.877942Z","iopub.execute_input":"2025-04-05T04:36:07.878240Z","iopub.status.idle":"2025-04-05T04:37:32.734223Z","shell.execute_reply.started":"2025-04-05T04:36:07.878216Z","shell.execute_reply":"2025-04-05T04:37:32.733300Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 45.61%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Now that we have evaluated our initial model, which uses a simple Neural Network architecture and Xavier weight initialization, we achieved an accuracy of only **45.61%** on the testing set. \n\nTo improve the model's performance, we will now apply several refinement techniques such as:\n- Adding **Dropout layers** to reduce overfitting\n- Tuning **batch size** and **number of epochs**\n- Experimenting with different **learning rates** and **optimizer settings**\n\nThese adjustments will help us better understand how each factor influences the models ability to generalize.\n","metadata":{}},{"cell_type":"markdown","source":"## 3. Tune the Model","metadata":{}},{"cell_type":"markdown","source":"### Step-by-Step Model Refinement Plan\n\nAfter evaluating the initial model, we will now gradually refine our neural network using the following steps:\n\n1. **Wider the Model and Increasing Epoch**\n   -  More neurons = More capacity to learn complex patterns in image data (adding layer and depth)\n   -  Incresing epoch in some extent can help the machine learns better\n  \n2. **Adding Regularizations**\n   - Penalize large weights to prevent extreme values\n\n3. **Batch Normalizations** \n   - Normalize layer outputs to stabilize training\n\n4. **Adding Dropout Layer** \n   - Randomly disable neurons to prevent co-adaptation (overfitting)\n\n5. **Transition to CNN**\n    - CNNs excel at spatial patterns in images","metadata":{}},{"cell_type":"markdown","source":"#### Step 1: Wider Model First","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass WiderNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 128)    \n        self.fc4 = nn.Linear(128, 10)   \n    \n        self.__initialize_weights__()\n    \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))\n        return self.fc4(x)  # No softmax (included in CrossEntropyLoss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:31:35.974089Z","iopub.execute_input":"2025-04-04T16:31:35.974378Z","iopub.status.idle":"2025-04-04T16:31:35.980533Z","shell.execute_reply.started":"2025-04-04T16:31:35.974355Z","shell.execute_reply":"2025-04-04T16:31:35.979603Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model = WiderNN()\ndevice = torch.device('cuda')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:31:36.344418Z","iopub.execute_input":"2025-04-04T16:31:36.344686Z","iopub.status.idle":"2025-04-04T16:42:17.727773Z","shell.execute_reply.started":"2025-04-04T16:31:36.344663Z","shell.execute_reply":"2025-04-04T16:42:17.727050Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1478.5893 - Accuracy: 31.47%\nEpoch [2/10] - Loss: 1317.3665 - Accuracy: 39.38%\nEpoch [3/10] - Loss: 1243.8024 - Accuracy: 42.99%\nEpoch [4/10] - Loss: 1196.1730 - Accuracy: 45.11%\nEpoch [5/10] - Loss: 1158.7659 - Accuracy: 46.90%\nEpoch [6/10] - Loss: 1124.0562 - Accuracy: 48.54%\nEpoch [7/10] - Loss: 1100.3315 - Accuracy: 49.54%\nEpoch [8/10] - Loss: 1074.1911 - Accuracy: 50.72%\nEpoch [9/10] - Loss: 1049.5730 - Accuracy: 52.16%\nEpoch [10/10] - Loss: 1023.9396 - Accuracy: 53.09%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"evaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:42:17.728768Z","iopub.execute_input":"2025-04-04T16:42:17.729077Z","iopub.status.idle":"2025-04-04T16:42:48.591256Z","shell.execute_reply.started":"2025-04-04T16:42:17.729042Z","shell.execute_reply":"2025-04-04T16:42:48.590351Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 48.06%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import torch.nn as nn\n\nclass WiderNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.fc2 = nn.Linear(1024, 256)   \n        self.fc3 = nn.Linear(256, 10)   \n    \n        self.__initialize_weights__()\n    \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc3(x)  # No softmax (included in CrossEntropyLoss)\n\nmodel = WiderNN()\ndevice = torch.device('cuda')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=10)\n\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:16:40.793066Z","iopub.execute_input":"2025-04-04T16:16:40.793373Z","iopub.status.idle":"2025-04-04T16:30:34.222163Z","shell.execute_reply.started":"2025-04-04T16:16:40.793350Z","shell.execute_reply":"2025-04-04T16:30:34.221423Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1471.1822 - Accuracy: 32.63%\nEpoch [2/10] - Loss: 1303.9041 - Accuracy: 40.51%\nEpoch [3/10] - Loss: 1235.5686 - Accuracy: 43.68%\nEpoch [4/10] - Loss: 1194.7099 - Accuracy: 45.57%\nEpoch [5/10] - Loss: 1162.1605 - Accuracy: 47.10%\nEpoch [6/10] - Loss: 1130.9000 - Accuracy: 48.45%\nEpoch [7/10] - Loss: 1108.6801 - Accuracy: 49.37%\nEpoch [8/10] - Loss: 1084.9758 - Accuracy: 50.62%\nEpoch [9/10] - Loss: 1063.1674 - Accuracy: 51.66%\nEpoch [10/10] - Loss: 1049.4077 - Accuracy: 52.11%\nTest Accuracy: 51.04%\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import torch.nn as nn\n\nclass WiderNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 512)\n        self.fc2 = nn.Linear(512, 256)   \n        self.fc3 = nn.Linear(256, 10)   \n    \n        self.__initialize_weights__()\n    \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc3(x)  # No softmax (included in CrossEntropyLoss)\n\nmodel = WiderNN()\ndevice = torch.device('cuda')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=10)\n\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T17:12:30.152699Z","iopub.execute_input":"2025-04-04T17:12:30.152987Z","iopub.status.idle":"2025-04-04T17:24:11.495447Z","shell.execute_reply.started":"2025-04-04T17:12:30.152963Z","shell.execute_reply":"2025-04-04T17:24:11.494414Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1459.0515 - Accuracy: 33.16%\nEpoch [2/10] - Loss: 1300.5952 - Accuracy: 40.54%\nEpoch [3/10] - Loss: 1236.2775 - Accuracy: 43.47%\nEpoch [4/10] - Loss: 1190.0324 - Accuracy: 45.69%\nEpoch [5/10] - Loss: 1153.8505 - Accuracy: 47.21%\nEpoch [6/10] - Loss: 1130.6043 - Accuracy: 48.48%\nEpoch [7/10] - Loss: 1107.2007 - Accuracy: 49.39%\nEpoch [8/10] - Loss: 1089.4742 - Accuracy: 50.30%\nEpoch [9/10] - Loss: 1065.9612 - Accuracy: 51.24%\nEpoch [10/10] - Loss: 1046.5271 - Accuracy: 52.41%\nTest Accuracy: 50.46%\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"**Result**\n\nIt is important to note that increasing the number of layers or neurons in a neural network does not always lead to better performance. In the experiments conducted, a four-layer networkwhen configured similarly to the three-layer modelactually resulted in poorer accuracy.\n\nAdditionally, modifying the number of neurons in a three-layer configuration showed that both too few and too many neurons can negatively impact performance. These findings highlight that model depth and width must be carefully balanced based on the data and training configuration.\n\nAfter several trials, the most effective result was achieved using a three-layer model defined as WiderNN, which includes:\n\n- 1024 neurons in the first hidden layer,\n\n- 256 neurons in the second hidden layer,\n\n- 10-unit output layer.\n\nThis model, trained using Xavier initialization and the Adam optimizer over 10 epochs, reached a test accuracy of 51%, which is a significant improvement over the baseline result of 46%. This outcome suggests that a wider architecturewhen properly tunedcan lead to better generalization, even without increasing the depth of the network.","metadata":{}},{"cell_type":"markdown","source":"#### Step 2: Adding Regularizations and Batch Normalizations","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass NormalizedNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)  # BatchNorm after FC1\n        self.fc2 = nn.Linear(1024, 256)\n        self.bn2 = nn.BatchNorm1d(256)   # BatchNorm after FC2\n        self.fc3 = nn.Linear(256, 10)\n        \n        self.__initialize_weights__()\n    \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = F.relu(x)\n        \n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = F.relu(x)\n        \n        return self.fc3(x)\n\n# Initialize with L2 regularization (weight decay)\nmodel = NormalizedNN().to('cuda')\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 penalty\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=10)\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:27:07.285650Z","iopub.execute_input":"2025-04-05T05:27:07.285938Z","iopub.status.idle":"2025-04-05T05:39:01.405409Z","shell.execute_reply.started":"2025-04-05T05:27:07.285914Z","shell.execute_reply":"2025-04-05T05:39:01.404540Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1266.6492 - Accuracy: 42.16%\nEpoch [2/10] - Loss: 1099.7229 - Accuracy: 49.83%\nEpoch [3/10] - Loss: 1030.6368 - Accuracy: 53.10%\nEpoch [4/10] - Loss: 981.4558 - Accuracy: 55.56%\nEpoch [5/10] - Loss: 946.3150 - Accuracy: 56.89%\nEpoch [6/10] - Loss: 909.4443 - Accuracy: 58.73%\nEpoch [7/10] - Loss: 879.9884 - Accuracy: 59.92%\nEpoch [8/10] - Loss: 849.6495 - Accuracy: 61.42%\nEpoch [9/10] - Loss: 823.9593 - Accuracy: 62.54%\nEpoch [10/10] - Loss: 791.4134 - Accuracy: 64.06%\nTest Accuracy: 46.86%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass NormalizedNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)  # BatchNorm after FC1\n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)   # BatchNorm after FC2\n        self.fc3 = nn.Linear(512, 128)\n        self.bn3 = nn.BatchNorm1d(128)   # BatchNorm after FC3\n        self.fc4 = nn.Linear(128, 10)\n        \n        self.__initialize_weights__()\n    \n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = F.relu(x)\n        \n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = F.relu(x)\n        \n        x = self.fc3(x)\n        x = self.bn3(x)\n        x = F.relu(x)\n        \n        return self.fc4(x)\n\nmodel = NormalizedNN().to('cuda')\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=10)\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:39:01.406420Z","iopub.execute_input":"2025-04-05T05:39:01.406681Z","iopub.status.idle":"2025-04-05T05:50:01.861962Z","shell.execute_reply.started":"2025-04-05T05:39:01.406657Z","shell.execute_reply":"2025-04-05T05:50:01.861268Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1265.1250 - Accuracy: 42.28%\nEpoch [2/10] - Loss: 1104.8493 - Accuracy: 49.43%\nEpoch [3/10] - Loss: 1037.5730 - Accuracy: 52.55%\nEpoch [4/10] - Loss: 988.7477 - Accuracy: 54.69%\nEpoch [5/10] - Loss: 945.9653 - Accuracy: 56.88%\nEpoch [6/10] - Loss: 909.9340 - Accuracy: 58.76%\nEpoch [7/10] - Loss: 878.4963 - Accuracy: 60.05%\nEpoch [8/10] - Loss: 847.1903 - Accuracy: 61.47%\nEpoch [9/10] - Loss: 811.4753 - Accuracy: 63.14%\nEpoch [10/10] - Loss: 779.4842 - Accuracy: 64.65%\nTest Accuracy: 53.94%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"#### Step 3: Add Dropout Layers","metadata":{}},{"cell_type":"markdown","source":"Now, we see that more layers, will give better result since we are doing the normalizations and regularizations properly. But you will see the testing result is not that proper, we may put some dropout layers to prevent overfitting, which is happening in previous training. ","metadata":{}},{"cell_type":"code","source":"class NormalizedNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)\n        self.drop1 = nn.Dropout(0.25)\n        \n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n        self.drop2 = nn.Dropout(0.15)\n        \n        self.fc3 = nn.Linear(512, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        \n        self.fc4 = nn.Linear(128, 10)\n\n        self.__initialize_weights__()\n\n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        \n        x = F.relu(self.bn1(self.fc1(x)))\n        x = self.drop1(x)\n        \n        x = F.relu(self.bn2(self.fc2(x)))\n        x = self.drop2(x)\n        \n        x = F.relu(self.bn3(self.fc3(x)))\n        return self.fc4(x)\n\nmodel = NormalizedNN().to('cuda')\noptimizer = optim.AdamW(model.parameters(), lr=0.0008,\n                     weight_decay=5e-5)\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=15)\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:51:34.764068Z","iopub.execute_input":"2025-04-05T08:51:34.764337Z","iopub.status.idle":"2025-04-05T09:07:36.771554Z","shell.execute_reply.started":"2025-04-05T08:51:34.764316Z","shell.execute_reply":"2025-04-05T09:07:36.770810Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/15] - Loss: 1307.1127 - Accuracy: 40.30%\nEpoch [2/15] - Loss: 1147.7510 - Accuracy: 47.63%\nEpoch [3/15] - Loss: 1078.3876 - Accuracy: 50.96%\nEpoch [4/15] - Loss: 1024.2862 - Accuracy: 53.19%\nEpoch [5/15] - Loss: 980.1110 - Accuracy: 55.38%\nEpoch [6/15] - Loss: 941.5788 - Accuracy: 57.06%\nEpoch [7/15] - Loss: 904.3092 - Accuracy: 58.82%\nEpoch [8/15] - Loss: 876.2708 - Accuracy: 60.08%\nEpoch [9/15] - Loss: 842.5606 - Accuracy: 61.88%\nEpoch [10/15] - Loss: 809.6519 - Accuracy: 63.24%\nEpoch [11/15] - Loss: 779.6401 - Accuracy: 64.50%\nEpoch [12/15] - Loss: 751.7934 - Accuracy: 65.65%\nEpoch [13/15] - Loss: 726.1812 - Accuracy: 67.05%\nEpoch [14/15] - Loss: 694.2351 - Accuracy: 68.45%\nEpoch [15/15] - Loss: 666.4591 - Accuracy: 69.64%\nTest Accuracy: 55.89%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"class FCNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)\n        self.drop1 = nn.Dropout(0.3)\n        \n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n        self.drop2 = nn.Dropout(0.2)\n        \n        self.fc3 = nn.Linear(512, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        \n        self.fc4 = nn.Linear(128, 10)\n\n        self.__initialize_weights__()\n\n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        \n        x = F.relu(self.bn1(self.fc1(x)))\n        x = self.drop1(x)\n        \n        x = F.relu(self.bn2(self.fc2(x)))\n        x = self.drop2(x)\n        \n        x = F.relu(self.bn3(self.fc3(x)))\n        return self.fc4(x)\n\nmodel = FCNModel().to('cuda')\noptimizer = optim.AdamW(model.parameters(), lr=0.0008,\n                     weight_decay=5e-5)\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=15)\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T09:07:36.772606Z","iopub.execute_input":"2025-04-05T09:07:36.772867Z","iopub.status.idle":"2025-04-05T09:24:11.293889Z","shell.execute_reply.started":"2025-04-05T09:07:36.772844Z","shell.execute_reply":"2025-04-05T09:24:11.293004Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/15] - Loss: 1320.4592 - Accuracy: 39.52%\nEpoch [2/15] - Loss: 1164.5300 - Accuracy: 47.06%\nEpoch [3/15] - Loss: 1093.7390 - Accuracy: 50.10%\nEpoch [4/15] - Loss: 1045.9785 - Accuracy: 52.44%\nEpoch [5/15] - Loss: 1009.3111 - Accuracy: 53.96%\nEpoch [6/15] - Loss: 968.8501 - Accuracy: 55.98%\nEpoch [7/15] - Loss: 940.2675 - Accuracy: 57.44%\nEpoch [8/15] - Loss: 908.8703 - Accuracy: 58.47%\nEpoch [9/15] - Loss: 881.2774 - Accuracy: 59.78%\nEpoch [10/15] - Loss: 852.4214 - Accuracy: 61.17%\nEpoch [11/15] - Loss: 828.6302 - Accuracy: 62.13%\nEpoch [12/15] - Loss: 800.4585 - Accuracy: 63.49%\nEpoch [13/15] - Loss: 779.8859 - Accuracy: 64.52%\nEpoch [14/15] - Loss: 750.4859 - Accuracy: 65.82%\nEpoch [15/15] - Loss: 728.2759 - Accuracy: 66.75%\nTest Accuracy: 57.38%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"class FCNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(3*32*32, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)\n        self.drop1 = nn.Dropout(0.4)\n        \n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n        self.drop2 = nn.Dropout(0.3)\n        \n        self.fc3 = nn.Linear(512, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        \n        self.fc4 = nn.Linear(128, 10)\n\n        self.__initialize_weights__()\n\n    def __initialize_weights__(self):\n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight)\n                if layer.bias is not None:\n                    nn.init.zeros_(layer.bias)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        \n        x = F.relu(self.bn1(self.fc1(x)))\n        x = self.drop1(x)\n        \n        x = F.relu(self.bn2(self.fc2(x)))\n        x = self.drop2(x)\n        \n        x = F.relu(self.bn3(self.fc3(x)))\n        return self.fc4(x)\n\nmodel = FCNModel().to('cuda')\noptimizer = optim.AdamW(model.parameters(), lr=0.0008,\n                     weight_decay=5e-5)\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, cifar_train_loader, criterion, optimizer, epochs=15)\nevaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T09:42:15.856659Z","iopub.execute_input":"2025-04-05T09:42:15.856973Z","iopub.status.idle":"2025-04-05T09:59:21.030491Z","shell.execute_reply.started":"2025-04-05T09:42:15.856947Z","shell.execute_reply":"2025-04-05T09:59:21.029764Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/15] - Loss: 1355.5544 - Accuracy: 38.26%\nEpoch [2/15] - Loss: 1197.5632 - Accuracy: 45.37%\nEpoch [3/15] - Loss: 1134.1146 - Accuracy: 48.40%\nEpoch [4/15] - Loss: 1090.0538 - Accuracy: 50.27%\nEpoch [5/15] - Loss: 1055.2285 - Accuracy: 51.55%\nEpoch [6/15] - Loss: 1024.8940 - Accuracy: 53.34%\nEpoch [7/15] - Loss: 999.8150 - Accuracy: 54.52%\nEpoch [8/15] - Loss: 970.3100 - Accuracy: 55.75%\nEpoch [9/15] - Loss: 947.0821 - Accuracy: 56.56%\nEpoch [10/15] - Loss: 925.5083 - Accuracy: 57.84%\nEpoch [11/15] - Loss: 900.3910 - Accuracy: 59.21%\nEpoch [12/15] - Loss: 884.0985 - Accuracy: 59.67%\nEpoch [13/15] - Loss: 864.0871 - Accuracy: 60.48%\nEpoch [14/15] - Loss: 845.5849 - Accuracy: 61.62%\nEpoch [15/15] - Loss: 823.9721 - Accuracy: 62.28%\nTest Accuracy: 57.12%\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"We actually have found out our FCNModel on the above, while we gained 57.12% accuracy only. MLPs struggle with CIFAR-10 (max ~60% accuracy) because they flatten RGB images, destroying crucial spatial relationships between pixels - unlike MNIST, where simple grayscale digit patterns are easily learned (90%+ accuracy). The 60% benchmark represents MLP's fundamental limitation with complex image data, as they lack convolutional layers' ability to detect local features like edges and textures. While CNNs naturally preserve 2D structure through filters and pooling to achieve 80-95% accuracy, MLPs force-learn pixel correlations through brute-force connections. Our result is strong for an MLP, proving the model extracted some meaningful patterns despite its architectural handicap. This gap demonstrates why CNNs dominate computer vision - they're biologically inspired to process hierarchical visual features that MLPs mathematically can't capture efficiently. The 60% ceiling should motivate to try out the CNN architecture, in hoping we can achieve the best result later.","metadata":{}},{"cell_type":"markdown","source":"#### Step 4 (BONUS) : Adding Convolutional Layer and Adding Learning Rate Scheduler","metadata":{}},{"cell_type":"markdown","source":"The 57.38% test accuracy ceiling with our MLP reveals a fundamental limitation: fully connected networks cannot effectively process spatial hierarchies in image data. While MLPs treat pixels as independent features (destroying local relationships), CNNs preserve 2D structure through:\n\n1. Convolutional Layers:\n    - Detect local patterns (edges, textures) via learnable filters\n    - Share weights across spatial locations (parameter efficiency)\n\n2. Hierarchical Feature Learning\n    - Stacked conv layers build complex features from simple primitives\n    - This architectural advantage allows CNNs to achieve >80% accuracy on CIFAR-10 where MLPs plateau at ~60%.\n\n**Learning Rate Synergy**\nWe simultaneously optimize the LR because:\n1. CNNs tolerate 1-10 higher LRs (0.001-0.01) than MLPs due to stabler gradients from:\n    - Weight sharing in conv layers\n    - Local connectivity patterns\n2. Techniques like OneCycleLR exploit this to accelerate convergence","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.pool = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n        self.fc2 = nn.Linear(512, 10)\n        self.dropout = nn.Dropout(0.5)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(self.dropout(x))) \n        return self.fc2(x)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNNModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(cifar_train_loader), epochs=20)\n\ndef train(model, loader, criterion, optimizer, scheduler, epochs):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            \n            optimizer.step()\n            scheduler.step()\n            \n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            running_loss += loss.item()\n        \n        train_acc = 100. * correct / total\n        print(f'Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(loader):.4f} | Acc: {train_acc:.2f}% | LR: {scheduler.get_last_lr()[0]:.6f}')\n\ndef evaluate(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    test_acc = 100. * correct / total\n    print(f'Test Accuracy: {test_acc:.2f}%')\n    return test_acc\n\ntrain(model, cifar_train_loader, criterion, optimizer, scheduler, epochs=20)\nbest_acc = evaluate(model, cifar_test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:09:20.583427Z","iopub.execute_input":"2025-04-05T13:09:20.583799Z","iopub.status.idle":"2025-04-05T13:35:31.588553Z","shell.execute_reply.started":"2025-04-05T13:09:20.583770Z","shell.execute_reply":"2025-04-05T13:35:31.587622Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20 | Loss: 1.3967 | Acc: 50.80% | LR: 0.001043\nEpoch 2/20 | Loss: 1.0730 | Acc: 62.00% | LR: 0.002801\nEpoch 3/20 | Loss: 0.9892 | Acc: 65.73% | LR: 0.005202\nEpoch 4/20 | Loss: 0.9474 | Acc: 67.47% | LR: 0.007602\nEpoch 5/20 | Loss: 0.9069 | Acc: 69.50% | LR: 0.009358\nEpoch 6/20 | Loss: 0.8530 | Acc: 71.44% | LR: 0.010000\nEpoch 7/20 | Loss: 0.7919 | Acc: 73.44% | LR: 0.009874\nEpoch 8/20 | Loss: 0.7362 | Acc: 75.30% | LR: 0.009504\nEpoch 9/20 | Loss: 0.6775 | Acc: 77.36% | LR: 0.008908\nEpoch 10/20 | Loss: 0.6160 | Acc: 79.34% | LR: 0.008116\nEpoch 11/20 | Loss: 0.5672 | Acc: 81.05% | LR: 0.007168\nEpoch 12/20 | Loss: 0.5048 | Acc: 83.04% | LR: 0.006111\nEpoch 13/20 | Loss: 0.4476 | Acc: 84.92% | LR: 0.004999\nEpoch 14/20 | Loss: 0.3808 | Acc: 87.03% | LR: 0.003886\nEpoch 15/20 | Loss: 0.3292 | Acc: 88.61% | LR: 0.002829\nEpoch 16/20 | Loss: 0.2776 | Acc: 90.55% | LR: 0.001881\nEpoch 17/20 | Loss: 0.2353 | Acc: 91.89% | LR: 0.001090\nEpoch 18/20 | Loss: 0.2052 | Acc: 92.81% | LR: 0.000495\nEpoch 19/20 | Loss: 0.1847 | Acc: 93.54% | LR: 0.000125\nEpoch 20/20 | Loss: 0.1810 | Acc: 93.69% | LR: 0.000000\nTest Accuracy: 83.94%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"Using this model, we can gain 83% accuracy on the testing period which is a nice and decent number.","metadata":{}},{"cell_type":"markdown","source":"## 4. Result","metadata":{}},{"cell_type":"markdown","source":"In this project, various strategies were applied to improve the performance of a neural network for image classification tasks. The following key points summarize the effects of each approach:\n\n1. Adding Depth and Width: Increasing the depth (adding more layers) and width (increasing the number of neurons in each layer) provided a slight improvement in performance, but it also introduced challenges like overfitting. Specifically, while training accuracy increased, the testing accuracy did not improve proportionally. This suggests that while a larger network can capture more complex patterns, it may also become more prone to overfitting if not properly regularized. While, increasing the number of epochs will be also helping to increase the testing accuracy value, but at some extent it will not give significant impact on the testing accuracy. Hence, it will be better if you find out the best epoch for your model.\n\n2. Regularization: Adding regularization techniques, such as L2 regularization (weight decay), helped reduce overfitting by penalizing large weights, encouraging the model to learn simpler, more generalizable patterns. Regularization proved essential in achieving a better balance between training and testing accuracy, stabilizing the model's performance.\n\n3. Batch Normalization: Batch normalization significantly improved training stability by normalizing the activations within each layer, allowing the network to train faster and more reliably. It reduced the sensitivity to weight initialization, enabled higher learning rates, and led to more consistent results. It also helped in improving the model's ability to generalize.\n\n4. Learning Rate Adjustments: Modifying the learning rate played a crucial role in the model's training efficiency. A learning rate of 0.01 was found to be effective for the CNN Model, while learning rate of 0.001 proved to be better on the MLP Model. Eventhough we know that smaller learning slowed down the learning process and larger rates led to instability and poor convergence. But once again, it also depends on the model.\n\n5. Why Use CNN for Image Data?: Convolutional Neural Networks (CNNs) are designed to excel at image data by leveraging their ability to capture spatial hierarchies in images. Unlike fully connected networks, CNNs automatically learn the spatial features of images through convolutions, making them far more efficient and accurate for image classification tasks. Using CNNs drastically improved the models performance compared to fully connected architectures, particularly in capturing local patterns and reducing the number of parameters.","metadata":{}},{"cell_type":"markdown","source":"That will be the end of this packed notebook. I hope you guys get the essential on exploring which model is suitable with your dataset, since each dataset has it s own uniquness and features. Thank you for reading until the end.","metadata":{}}]}