{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11878665,"sourceType":"datasetVersion","datasetId":7465275}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recurrent Neural Network on Cifar-10 Datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Hello everyone and Prof Di Bo Ya. My name is Denzel Elden Wijaya, and in this notebook, I will demonstrate how to implement a Recurrent Neural Network on the Cifar-10 Datasets. I will extract the raw data and create a custom dataset class that inherits from `torch.utils.data.Dataset`. This custom dataset will then be passed to `torch.utils.data.DataLoader` to enable efficient data loading during training. We will also find out\n1. How to feed images into an RNN Model\n2. The effect of neuron number in the hidden layer\n3. The number of hidden layers\n4. Test both Vanilla RNN and LSTM, and the performance difference","metadata":{}},{"cell_type":"markdown","source":"The process will include these steps:\n1. Load and Prepare the Dataset\n2. Build the initial RNN Model\n3. Model Experiment Testing\n4. Conclusion","metadata":{}},{"cell_type":"markdown","source":"## 1. Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass CifarDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_to_idx = {}\n\n        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n            class_path = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_path):\n                self.class_to_idx[class_name] = idx\n                for file_name in os.listdir(class_path):\n                    if file_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                        self.image_paths.append(os.path.join(class_path, file_name))\n                        self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        label = self.labels[index]\n        image = Image.open(image_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:43:08.873265Z","iopub.execute_input":"2025-05-20T08:43:08.873747Z","iopub.status.idle":"2025-05-20T08:43:16.175938Z","shell.execute_reply.started":"2025-05-20T08:43:08.873717Z","shell.execute_reply":"2025-05-20T08:43:16.175360Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar-dataset/cifar10_train\", transform=transform)\ntest_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar-dataset/cifar10_test\", transform=transform)\n\ncifar_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ncifar_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\nprint(f\"Total Training Data: {len(train_dataset)}\")\nprint(f\"Total Testing Data: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:43:16.176990Z","iopub.execute_input":"2025-05-20T08:43:16.177348Z","iopub.status.idle":"2025-05-20T08:43:17.016183Z","shell.execute_reply.started":"2025-05-20T08:43:16.177323Z","shell.execute_reply":"2025-05-20T08:43:17.015461Z"}},"outputs":[{"name":"stdout","text":"Total Training Data: 50000\nTotal Testing Data: 10000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# let's check the first image and its label\n\nfrom IPython.display import display\n\nimage, label = train_dataset[1]\nimage = transforms.ToPILImage()(image)\ndisplay(image)\n\nclass_names = list(train_dataset.class_to_idx.keys())\nlabel_name = class_names[label]\n\nprint(f\"Label: {label_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:43:17.017154Z","iopub.execute_input":"2025-05-20T08:43:17.017363Z","iopub.status.idle":"2025-05-20T08:43:17.079726Z","shell.execute_reply.started":"2025-05-20T08:43:17.017347Z","shell.execute_reply":"2025-05-20T08:43:17.078990Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAEPklEQVR4AXWWS4scVRTHu6q6O20Y0cgkBCainQdINnESyPjCGfE1C3Et+iFEXGclgQgugn4BUSGQXcZNNkFwrYiLmCAqJlFQXGSGnu6uR1eVv3NP15nbtzo1za1zz/mf/3ncU1UT/fbnvY67oijyBd3WdY3SZASVUZpJBfVVvWiqqiorhNgMvgALNi5f6ctmMsECKyySrCRjCRDY0BBecbZKtMV46tX2RWNKBAkQeKIxRCBbPN9rKbimB1GH3/IWuXTD/iwl0pBmslzrTi0nQIvUZoggR9MjmGykbY3vjswhdOXWzI+Z2xo1oVeTZWouvgAmjqU3DJIECC6cHY/MAIJyKS+aYKu+j4wXnIHxGpF5mqCMwWrhm3jkQX4UEXXxDMx+GDOZAIXKGhIZQWWLqi3XqV7SIsP5bkrUJDgfMCga/oOugnHUVCCwMIBlyin1+32euPlxuUdPQ4Jh+OIkETA/x5flWTkrNYNGJ7V2lRFPJXLx6ySK8yz//rtbt2///MKLLz35xBGuJOkBY7rLcpZNp/vjUZZldZQUbLP05PDk8eNrsGkSrjjkTvT7vfukmSRJExxM1Et6X3395eVPLvHGOnToMBmtrDwOmiTImQBJ3F17ei1N0x9/+AnH4anh1c+/WF+/UFW0RTpDweBxlwqUHUFjsDICeZGurAz2R5M8S8k7z6arR49NJ+PRaLcqo4sXN765dr2K4m9v7JRFcf7C+VNnzhRF0TDwHMAuBzM/A2NXwRUYzwrS75NPmReDwWMbGxvUsbNz45WXt849v97r9cs6eu/9DyiLFmXp1CPRCgjgHbIdIDh8ppPs6OqxtRMndnf37vxy5+HDvbt3f33zrbe3XnvjyqefDQaHZ6V0YTza48bocuxS+nzo5yNEotIin1prBMxpPvPscHt7e388eefdzmQ8ee7s2c3NTb4iSbcPu3ShU8dJR46yuVyUyJ2EPi61tEhL01VTIAFm4+bNW2mWf/jRx69uvU5VeV7QB4ZBph834RVqTdE5ys5pnNGZoj/uP1BqherKqDz4+6///v3nqSOrw9On0zyvmbQ4TmJ6EXN48hKQhaENP00wuBHSvlQSQJ8AvwJA3V63m/SKGTOS8VJnsMgtkXZSANT8mkJEd9Al1OzQMP0s8wcNtF5WDTPHs+Y+GNArl960CcLoaGUWobP8UMsR1pW+RcIATSB6SQ/wxNF13LWbCO7PspEYxm6+VhCuC++iOZUBm8RdBEmcS29tJKQ+r22lleKmWepmccUSWG1rjCoEerboFyqAGZXhNFCgUS5MwNrIxdxkN68AyTyRA8+lGpTB1fYCIP9V2MUeue2msdXUBhheaw0ABy0ygwnm2daYSQUAj2rAvEWYDeHLbSLTGN40viAh5YFwH301+Gnql1LzgkhNxugj8VW9WVXDltcltvAMNJh8uZqqTVBTe10az2D/A38CY+KoLPzAAAAAAElFTkSuQmCC","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2AU6kAzXmzfGrRI9TuLBtK1RpIpGjXykRt+3qcbvY0yT0vFMccVyemePJNb01L/SvC+sXVs0nlBgYUOcZzgvnHPXpXW8lASMEjkelADhxzXLab8PNAsZPOntEvrhZmljmuY13R5OcDaBkc9811QpwoAZHEkMKRRIqRoAqoowFA6AChulSdqjfpQB//9k="},"metadata":{}},{"name":"stdout","text":"Label: airplane\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_iter = iter(cifar_train_loader)\nimages, labels = next(data_iter)\nfor i in range(10):\n    image = transforms.ToPILImage()(images[i])\n    display(image)\n    print(f\"Label: {class_names[labels[i]]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:43:17.125189Z","iopub.execute_input":"2025-05-20T08:43:17.125722Z","iopub.status.idle":"2025-05-20T08:43:17.471413Z","shell.execute_reply.started":"2025-05-20T08:43:17.125682Z","shell.execute_reply":"2025-05-20T08:43:17.470834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDB1W5htLlTbRzxh+qGTcXIPyheOO9NfxYhgewmsHfyGLqxcZRu49M1S1qe4jltIod6zGJvmdMOgPf/AGTx1rJsLcFXPmSLg4JH8Vcjm1dmdrli48QPeXLsLEGNANgkByp+orUh1YXBg82IJvOVYNkkdKoWaXU6ENKm1cAjoo9Pcn2xRe2c8V1GUDy5l8pCybS+ByR7Ang96XM3qDiti9dW90dQL3kR8+ZyHKvvXO0FRuNJJpxs23s4SKYBkOc4H93/APVXcXHh+a8CmYLzhWwQC+KUaVFFJsuELsVCxxnPyhe5HcnPWtXTuCucfbC0ktZbuWFcxPtgXGHdvrWvo9oXtze3IZ5Y/ljyMbFA6DPvUt3otwsflQQq8an5Tt+ZeSf69atvp8VneRu8zu91GsIjBLICMnj04BpqDXQD/9k="},"metadata":{}},{"name":"stdout","text":"Label: frog\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAFnElEQVR4AT3WyU6WTRAFYIZXwAFkBtFIEEJgATtWrLkKroNL8R7YuHbJBhIMMTExYAgQRoGIKAKiDMr/NIffSmyqq6tOnarqtz9rNzc3//z5c3t7m7Wuru7Bgwd///799etXY2MjhWxtbb1+/XpwcHBqaurNmzdNTU0zMzM8b25uampq4lNVFbfZ2dmGhobfv393d3c3NzfzqeDyK1pVdJmur69ZJO7o6BDv6NGjRxMTE8+ePQPd29vb1dUF4urqqr6+nsP5+TlOcFtbW5H4/PkzHUjQatfX14Fyra2txUWATEdHR2/fvp2cnOT048ePV69eSeP04uLi5OREcZ2dneEkzdevXzFQrlhFLC4uUtrb260yVQ5SqQSg6RQQcKVhWVlZsY6MjGD98OFDNM/OznDihiZPrUhXMaBzDpQtfhUKAcWIxPrz5081AeJ6enq6u7urMyIBpUS0OItNcxh5EgmeP3+OGTaKYKkuLy/RCQWZhNmKpDjOqay6TwCxc0aNIqXm0AWKspXY5HZ2dqzchBdvQJyA2uuMqgUj0tbWtre39+XLF+N9/PhxUiYHrH+s2fW6tLuqrKK0Lm7aUJfxSoACOsiurq5ub2+3tLTs7+8vLy+7M4plDyIFXyt/wmi1BV3g6uo49/X1PXnyxBZsmapjLTs8PATqkijCge2LFy+mp6d7enoMgHdIKTRKciQrXFud4CbT06dPrURLypCdQXQF19bWjo+PwY2Njbkt/DQQwZBIDs7/krETPizQI26aaSWTOsrH5UDj7qbYxOTL6O/v98kYBvQE628yBSVFZH504tSa9FYtyWklXg5Y5vnp0ycJZJqbm/Ot52sSKUAwN9OLrid0yWyJOjJ2zo50xeWmgyrvydLS0rt37yQQwwpX5MLCgsjghlqCAyqKwl+XUUx9HAjiLgvJtO7fIhDEXeQq2C320b9//350dFSMTFlTblD486TrhpUeaAguizrY6eWz9pDZ079//24ALMaL3fz8vE/Gt6OBylKvycshX4n8/0lgRzalSOPySJAX0MDLLWJKHxFRmpWoxjFSbq0VivGIpBsGICsRmHlY5WAX5dPB6du3b1hW/nl5uCJOnEnJD0GuFJ8xUJKPmQUoQUKXQoJiyyhHGAunlPEwQedhnzSs6PgsNAeorPHWU2z4JAcFqCg+eoCyWvlQBLpFjtAqFYjnnReUqwMJDg4OfBwvX74UwEdPBQtwZJUVHBJ0F1od5scHOUb+QKSBXD4fpSFln2EUa1WZKifC23vn6U43WDwn7vTGxgZQxvHxcW3UCVklYDFIaJjdtwiptE8RFJN04CLxMCgWkSZs6/nzRsGle9SGhoa8V27ax48fh4eHgXL288fZT4Ie2JZbr3Z1EGFEGixsFUSkV406Pnz4AN2XAct99a3ksULC5dYoIlwpnnpGCEZbZm0AKMPSUNcREaC65Jiekeps3u2BgQH2/NjJSmcxKixNRaAqVUxS+v1PkgTQmcTIJEwRcZIpXLyAFP0tnb37bZGep5amyX79XR44eui3M+QqZziKzH2lqynQgMLCReRNuLEQhQJSesLDya1j5EPY+aN7f02hC4MohuAlEw9+nOiM2iIShFO9Dkc6o5WgFTeTF4so2PIrmrQSgCMUMXApYijGLh5r8emPYDnEguCTVRQ7BFsz00bdK/8TQVC8SB6sLIBidyTAnckNliPpQUssR7b8DRlr/obEKBNF7vJU2CSBlU4E8ObnVAJZCZ3REWieRFaZoPBESHpbuEIYefIp1xRxwilE8OLtFoGjI+WIA8UY+BCRgFiEW8GlgewZJAQisMzAH9ZUDdR3mIeTdz4xR+hLGXQKjuLliMWaNCyi7sDvL30Fi0kOij7kwXJDUEspqJkBixcpbCQLhBmCNk+eYpO19P3utwgsh/8AYm6ey71whFUAAAAASUVORK5CYII=","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1a4njhgkkY7SoPJPfFctpc51u7+y3sazNaIkm4n7kmP54NLrrXkjLIluEVScEvuEmDxlc9K1NP13TXhjSKPyJivzRCIjaemOBQBPb6ebKzS1tZPLhTO1RzgZz/WuM8Uae9vr0c+eZ4txYLjkcHP4YruheRHA5B9xisHxMTcC1mi2lV3I2R0zigBjXLM4/dyFTwcVDdTT2lr5scTM69QB8z/0qV4nbkQyHJwADTZEnQHIkwpHTvQBQS510u86rAFQcW/zM7/jwBUrebc2srzyusiuMxEYzU8ckwDOI2x7jpU8cbzBmfncMEYoA/9k="},"metadata":{}},{"name":"stdout","text":"Label: deer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDynUr02UogW2iVfKAK7y4xknAYdRnnP4VHbapNcFsxRbiWJ6jluG/MflUt/pd1fXMQtoYirBVHkNlO/wB3Pb+ua6O28L2iaXBLEx835kO4ffOewrCpVjTjdq51XnObinYzrPTfEGox/aLGwikjWQAMWx8yjC8E9h+dUIJLgag+nXNnFvjXy2jMm0YDZwWzxzzn8K72e21/T9F0ddL84rcN5cot49wTOPmPoRiud8T2Zt/Gc0cqWzMYw7tL8qEk/wAWKqMnLVomM5cyVzKa9vLXV4b2zeJnEYVHVcJk5GQvbH/16qWGvX1lq8Mk9zI8SyAyJ1BAPSrl9ptzeSC4WeXb5KuWa3YFhu2A4HA54/CrOn+Dbhpi8koIjeRXDRMOUGX6jtWnutWkTUpT524nr3hW/t5NFQiYOkrkx45257f0rzbxrCbfxqZw6eVJDkyzIWXcDzkY5rX8OQNHY3ejyO6q5QW0io6lGkBKjOPxqGRJ7XTWs7xTNPAN8V2EZii7tp4IwRmuZz5PdNqVCcpKTP/Z"},"metadata":{}},{"name":"stdout","text":"Label: dog\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAFMUlEQVR4AZXWyU9VWRAG8AYviogiIKKCEQcMqKABEpRoosGNwRj/QXYmLFm5cEmIC4iEKOKAEloGZVABBwQn+neteH15vLbtk3g9Q9VXX31V5zyKvn///u3bt79+js3NTTu3bt26f//+jh07ysvLb9682dLS8vXr1+Li4p9W//F/gHz+/LmoqChJ/yVJ5uHMvLS01LekpOTLly/j4+NNTU2CZTZ/Mvnw4cPLly95paRQhhvDXMg9e/Zs27YtKPz9Y+SZ/TT/5cWR/erqKmiSrKysvH///uPHjyl3iBmpmFdUVBCEN2Xevn374MGD48ePC5mZFZw8e/ZscHBw9+7dV65c4VhVVbWxsVFYVgFEQmR9fZ3p48ePX716ZScIF0RHCPdHjx4NDw/fvXuXDeVxKpaX7PJ81FYBBODGaHl5eWxsjI0YESbP3lLsffv2oc9F0rzAbt++vfjhw4fE4pbrU1ZWtnPnTjuMeJoIIAk1l3XkIXwwk6IBQd68nML99OkTLyyTFy9eVFdX792710FK70ckAaKRQOBiwJ2enub5+vVrhGpra/fv3w8C33fv3gkM2hdUTU1NZWWlaqsB+4TKas00oIMU+Xbt2gXXPqa67c2bN7dv3zah8vPnz2/cuHH58mUo0W98EXLa1tYWm+JxRDqx5gxIfHTiTjiOGiCuAJQdHR1VQwPW0aNHFUkejJeWljRYKMOFVgMDAydPnmxoaABIiURBFhYWBJCOL+0gPn36dGhoaGRkJFCk4rS+vl5aLvaJEyeePHnCUWHASeXSpUt1dXWyQYiNatFHPIETEEwJ5W3ghum9e/empqZsajA56Q3pX7x48erVq7gjtbi4yHN2dnZiYgK0ibuowgcOHMCjs7MzmHHEOH0qtK1S9/f3M1UPoFCUiw8RKIByR0eHquLhiqIpUZakuHDhwp07d9jjK1H01V8hJycnkVhbW0sDCEgWsp4/fx4L0JLlIJIq6QpLPsLbFNJXVYTBbG5u7ty5c6dPnz548CAEp8JYyl42RiI7Z9euXZN+gAqGHURVik4gow5BRTwoFMNDVAyYke7QoUNxxcKGwdmzZ+mTFpkR65mZGWeRuzshpDwU34BoaG3UxKMYf7j8lT0qH+Eh2DRMQPsCT3p6enp7e1tbW5lSjYLgGLlQgDzU4tkPNzG4qT/PuEeAAj0F/vFgxCSbJ8eOHWPd1dWFmi4mIppU0ioUdKTnSOS62qehuun97u7u9vZ20HYyRJPcJGI/0RunTp06fPgwOMdUBkpfrN0GbRPFsCmADEzgSkvDbIXLDQbKMtGL5AYnZVW1GwdQMPX+BC9YAkAXIzQJNr5GLm7ePGGNb4CGxCwsdSfdCEIruPKgHixHkVMGFL7ZMm9STERXDru8A26a78yZM3DNDWGCrDnpfPNcCi7T100GxNl6DO7IkSOkg5Wrg7nM8ja3usdOSkrFhLHORcHXjtgqFEduiUThOjL/0ww4NzY2KrVJNiISCAISSm1cfSTgslEDb5FvZv+bSUoTR6UuyEgkFzA09HeOF9fTAlq8+Jn8DXQcpQGghCC51hHPl4CS8IDPz89fv35dGO+HGALk2v/bPA2QtUdmlJuN5FxDN9mT1dzcTCU/gprifwTIhctiZBOnfq28yf7+6Ovrc4H9PAhDpcym4CRgf/1VWtDIJjtPsZdH73v+PC0eOOiWcZrbe1tBfknELhtEy4ZNz5QfcXc72hSKjoouYpZ55U0cpZYIbr3GeUR4esbjRVEPxZCT4mfx8uyzpf7+B6PZh4vSyivuAAAAAElFTkSuQmCC","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3S4Ed7pkwjIZJomAI7gg15r8OdY+yapLpkxxFOCVz2df8RVCDx74obR7e10TSrA7A0f2q8uPvEMekY56Yrl9L8Kazd30ja3qLqm4sY7EFGz9e3U0AfRCyxMm5XQr6g1zR1y7uNfv9KeJY44drRSp1YEA4P51xlvo2qabfWdho1tNDa7t+HHmA5IzvZuR3P1xXcSaNdR3tvdRNkEKksQOBxzkfrQBJoeh2traTqkYRjdTksBycyMev0Ncb4kW/0bUzAl3IIX+eMqcZB9cd69QAAzjA5zXF/EbTXudKtryIZNvMPNUNtLRnqAR07UAaXgtzPoQllZpJfNcM7nJ6+pro65H4dx3EPh1oroN5glzuIxuyB6111AH/2Q=="},"metadata":{}},{"name":"stdout","text":"Label: airplane\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCbVNDFp4he4dQY2PQjgVyviO1g0zU3HnKil8LkHk9cfqK9S8bKG0wyRthyRjaM15Bqq33iTWHi8tnitmypUgZ455/CuCldysb1EkrnXafqsV1pT2oZizLgAjGetcTqUfkxvC6jcjHj1Fdv4QsPtGmLcTqvnROysjHkDPH6Vz/iiKJdTYsAIxn5sdale7Nop3cEz1TVGW68LPNgHNuSox3wa8e0y0lXSFnS6ZJo/meNTksD69vzr0PT/EWmpoNvaajMDJ5RV0ycHkg/56Vgaha2+oFTpc7h1BgARMI0XbJPO78cU6clGTuKa5oo88s73UYdULadNLHNJKQFRvvexHevUtMbw/qN7FpmsN5V1PamZ5nYAKw+8pz0P6VV0P4YPcTiR7kwPnIcAkgn9K7PSfhppllOJp7l7iQd2UVrLlqapEQUon//2Q=="},"metadata":{}},{"name":"stdout","text":"Label: cat\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDmort7tZLFJy4PyFm6hgO3PUYqroF7qJdSxaYROY9pHzBQOx+uKraPK1vrryyr5sYbdlcgZ6V0cGu2mjI1xZ6G5uxE6hrrMyTdW3Bf4funpXCoaMulh5VfhaLGqq9/NFCLJ7j5S2Q2PmB5HsefxrJu5sW7CSOQBJF8xW48s/T/AD1rprfWBtS7bT7RZJQHdVZ1VSewXP61Bqt9p13biG709X3MPmE2dpOex6n8ahPl9063k+JcedJNepFpXhr+zLi4OqX1rGZsuuHwAByeo/p+NV7m5gs5C0EsV1bRSJ9onVztRWOB6Hjv/TrW/fXeh+IYEg1OxlaNTlWbIwfqDUUGh+DLSN40gCxSY8yDzXKvjpuXOD+NdUsPrqRhsfOhBxpvqZi6noqRtPFqMUjISyh3RVGOhPzE4FYV9rt5rV3FbJdItuxVkcuuWXJUtj6g1u3ml+H4ZGeztLYAtwBAoI/OswxWNuf3VnCvuFqqeDjuzWvm9aoktNLn/9k="},"metadata":{}},{"name":"stdout","text":"Label: truck\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDDkXiqcmQCa1HjyOlJb2qs++RTtXkADNcbaRag5OyMBm5JqtlmDGta7hV7yfZnbnjOKz2iKK3FadbCtY6q43rGRFEzyEcEDgfWmy7LNBncxZeT1LVHcatZQbg9yNyjOEG41UfxDZC2ZVklkbPClcH6ZrP2bb1NVNLYS2tZsPLKjLuztBHJqOe1Kgl12/73FZ412ZWEUCiKNieSNx/WnXmq6hGEa2YFQQrOYwDnnPatXBvW5k2tj//Z"},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDt7eTA5q0Jh0rMiEn8IJrI1zWoYdF1UJdJHc28TqUkO1g23IwDyeCCCOtUxHW+dgUxphisHw219ceGtPuLoN50kCu2R68j9MVqbXI6UARW1wARUk2laRqIxeabZ3GW3fvYVY59cmue8N65HqMvkS7C4Gc9z/nmuvSOER5xzUuzGhYoooE8uFdqdlycD6DsPYUOQBzSDb2JpJFGPvUkB//Z"},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDXigYOWBBz2xVW/wBbTT7wW/yE4G7jJBq/G44G7msG8tfNur672edcRgbd/Cpz29yK8jB1INtzM4PubdpePcRs7qiNnJG7t2p7y996HPoaxdBgvjPcpqEYhkG3Cg5ypz3rWNrEUZY5Mc8gc1NeUFN8mxMnroIkgx6j0xVaS4MkksKGMgyLkH14pyDIIcD6UkSIHZQoX5sn5eCfWuCm3F3IJJ7qWGRmEQZ5FC5XopGf05rM06O5tb2ZmA8uTqd+QPwrUwvciq5aNpSoKEr2Dc1aqSUeVCZ//9k="},"metadata":{}},{"name":"stdout","text":"Label: bird\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3JLoA4IGMdad9rUDkAV5sfHllJB5lt5skbDCybcDOeevpXPnWdfOttdG/b+z/ACm25IB347D0rS0TPmPYbq7RFLs6IgHLMQAPxryv4gfE02JGm6DPFLOUJlnTDBPYe9efeIPGeq6hZrYzXzyQMN0gIALHPAOPSuQluQFwOW69Kzc7aILmxcX8uh6QLKWNUE0pIZkyQMckHt2rMsbrWL+SNIry8kQ5BVGPy/4V6dqOk2GrIi3sTTIhyoZuhqrbeHNIsyzQQGPd97Eh5qFN2NOU4LUH1bQigizGkwwMoGOfxqG11jU7m4t1N0X3nDKI1weeh4r0mSw06EAtBH/wL/69VmutPgJEcSf8BWpdVRWocp//2Q=="},"metadata":{}},{"name":"stdout","text":"Label: truck\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 2. Build the Initial RNN Model","metadata":{}},{"cell_type":"markdown","source":"Recurrent Neural Networks (RNNs) are a type of neural network designed to process sequential data. Unlike feedforward networks, RNNs have internal memory that allows them to retain information about previous inputs, making them well-suited for tasks like:\n\n1. Text processing\n2. Time-series forecasting\n3. Audio analysis\n4. And in this case, processing image rows as sequences\n\nAlthough RNNs are typically used for sequential data like text, we can treat images as sequences. For example, a 32x32 RGB image can be seen as a sequence of 32 rows, each with 96 features (32 pixels  3 channels).","metadata":{}},{"cell_type":"markdown","source":"In this initial experiment, we implemented a simple Recurrent Neural Network (RNN) model using PyTorch's nn.RNN module. The CIFAR-10 images are reshaped to be compatible with RNNs by treating each image as a sequence of 32 steps (rows), where each step is a 96-dimensional vector (32 pixels  3 channels).\n\nThe RNN model configuration:\n1. RNN type: Vanilla RNN\n2. Number of layers: 1\n3. Hidden size: 128\n4. Activation: tanh (default in PyTorch RNN)\n5. Output: Last time step  Fully Connected  10 classes","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass OnlyOneRNN(nn.Module):\n    def __init__(self, input_size=96, hidden_size=128, num_classes=10):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        B = x.size(0)\n        x = x.permute(0, 2, 3, 1).reshape(B, 32, -1)\n\n        h_t = torch.zeros(B, self.hidden_size, device=x.device)\n\n        for t in range(x.size(1)): \n            x_t = x[:, t, :]\n            combined = torch.cat([x_t, h_t], dim=1)\n            h_t = torch.tanh(self.i2h(combined))\n\n        return self.fc(h_t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:37:10.026952Z","iopub.execute_input":"2025-05-20T11:37:10.027490Z","iopub.status.idle":"2025-05-20T11:37:10.033447Z","shell.execute_reply.started":"2025-05-20T11:37:10.027470Z","shell.execute_reply":"2025-05-20T11:37:10.032745Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_one_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss, correct = 0.0, 0\n    total = 0\n\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * x.size(0)\n        _, preds = outputs.max(1)\n        correct += preds.eq(y).sum().item()\n        total += y.size(0)\n\n    return running_loss / total, correct / total\n\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    running_loss, correct = 0.0, 0\n    total = 0\n\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            loss = criterion(outputs, y)\n\n            running_loss += loss.item() * x.size(0)\n            _, preds = outputs.max(1)\n            correct += preds.eq(y).sum().item()\n            total += y.size(0)\n    return running_loss / total, correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:37:10.311028Z","iopub.execute_input":"2025-05-20T11:37:10.311228Z","iopub.status.idle":"2025-05-20T11:37:10.317283Z","shell.execute_reply.started":"2025-05-20T11:37:10.311212Z","shell.execute_reply":"2025-05-20T11:37:10.316751Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"device = torch.device(\"cuda\")\n\nmodel = OnlyOneRNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nepochs = 10\nfor epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n    test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:37:11.539332Z","iopub.execute_input":"2025-05-20T11:37:11.539638Z","iopub.status.idle":"2025-05-20T11:49:15.400877Z","shell.execute_reply.started":"2025-05-20T11:37:11.539619Z","shell.execute_reply":"2025-05-20T11:49:15.400160Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Train Loss: 2.0749 Acc: 0.2300 | Test Loss: 1.9767 Acc: 0.2803\nEpoch 2/10 | Train Loss: 2.0121 Acc: 0.2520 | Test Loss: 1.9662 Acc: 0.2624\nEpoch 3/10 | Train Loss: 1.9502 Acc: 0.2792 | Test Loss: 1.9979 Acc: 0.2765\nEpoch 4/10 | Train Loss: 1.8904 Acc: 0.3015 | Test Loss: 1.9278 Acc: 0.2829\nEpoch 5/10 | Train Loss: 1.8521 Acc: 0.3209 | Test Loss: 1.8443 Acc: 0.3345\nEpoch 6/10 | Train Loss: 1.7945 Acc: 0.3407 | Test Loss: 1.8251 Acc: 0.3256\nEpoch 7/10 | Train Loss: 1.7617 Acc: 0.3514 | Test Loss: 1.7144 Acc: 0.3652\nEpoch 8/10 | Train Loss: 1.7998 Acc: 0.3344 | Test Loss: 1.7655 Acc: 0.3526\nEpoch 9/10 | Train Loss: 1.7476 Acc: 0.3549 | Test Loss: 1.6936 Acc: 0.3739\nEpoch 10/10 | Train Loss: 1.7060 Acc: 0.3715 | Test Loss: 1.6666 Acc: 0.3860\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"While the model does learn something (as seen in the accuracy improvement), the performance plateaus around ~38% accuracy, which is quite low for CIFAR-10.\n\nThis suggests that:\n1. The model cannot capture complex image patterns.\n2. Vanilla RNN may not be expressive enough to model image data effectively.\n\nBut, before we change into LSTM, which supports a better result, let's experiment with the number of layers and the hidden size to find out the best model","metadata":{}},{"cell_type":"markdown","source":"## 3. Model Experiment Testing","metadata":{}},{"cell_type":"markdown","source":"#### Varying Hidden Size","metadata":{}},{"cell_type":"markdown","source":"We aim to investigate how increasing the RNN's hidden layer size affects the models ability to classify CIFAR-10 images. A larger hidden size allows the model to learn more complex representations, but it may also lead to longer training time or overfitting.","metadata":{}},{"cell_type":"code","source":"hidden_sizes = [64, 128, 256]\n\nfor hidden_size in hidden_sizes:\n    print(\"Training RNN with hidden_size = {hidden_size}\")\n\n    model = OnlyOneRNN(input_size=96, hidden_size=hidden_size, num_classes=10).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(10):\n        train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n        test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n        print(f\"Epoch {epoch+1}/10 | \"\n              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n              f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T06:51:08.383621Z","iopub.execute_input":"2025-05-20T06:51:08.383891Z","iopub.status.idle":"2025-05-20T07:21:12.022622Z","shell.execute_reply.started":"2025-05-20T06:51:08.383872Z","shell.execute_reply":"2025-05-20T07:21:12.022049Z"}},"outputs":[{"name":"stdout","text":"\n Training RNN with hidden_size = 64\nEpoch 1/10 | Train Loss: 2.0534 Acc: 0.2353 | Test Loss: 1.9242 Acc: 0.2950\nEpoch 2/10 | Train Loss: 2.0260 Acc: 0.2507 | Test Loss: 1.9558 Acc: 0.2874\nEpoch 3/10 | Train Loss: 1.9794 Acc: 0.2717 | Test Loss: 1.9241 Acc: 0.2827\nEpoch 4/10 | Train Loss: 1.9085 Acc: 0.2981 | Test Loss: 1.8731 Acc: 0.3133\nEpoch 5/10 | Train Loss: 1.8522 Acc: 0.3170 | Test Loss: 1.8044 Acc: 0.3391\nEpoch 6/10 | Train Loss: 1.8305 Acc: 0.3260 | Test Loss: 2.0635 Acc: 0.2210\nEpoch 7/10 | Train Loss: 1.9127 Acc: 0.2958 | Test Loss: 1.8741 Acc: 0.3086\nEpoch 8/10 | Train Loss: 1.8531 Acc: 0.3157 | Test Loss: 1.8397 Acc: 0.3232\nEpoch 9/10 | Train Loss: 1.8247 Acc: 0.3248 | Test Loss: 1.8072 Acc: 0.3258\nEpoch 10/10 | Train Loss: 1.8249 Acc: 0.3254 | Test Loss: 1.8030 Acc: 0.3308\n\n Training RNN with hidden_size = 128\nEpoch 1/10 | Train Loss: 2.0936 Acc: 0.2224 | Test Loss: 2.2108 Acc: 0.2125\nEpoch 2/10 | Train Loss: 2.0128 Acc: 0.2554 | Test Loss: 1.9968 Acc: 0.2532\nEpoch 3/10 | Train Loss: 1.9098 Acc: 0.2907 | Test Loss: 1.9025 Acc: 0.2923\nEpoch 4/10 | Train Loss: 1.8683 Acc: 0.3109 | Test Loss: 1.8864 Acc: 0.3137\nEpoch 5/10 | Train Loss: 1.8118 Acc: 0.3307 | Test Loss: 1.7898 Acc: 0.3435\nEpoch 6/10 | Train Loss: 1.7613 Acc: 0.3525 | Test Loss: 1.7627 Acc: 0.3469\nEpoch 7/10 | Train Loss: 1.7352 Acc: 0.3587 | Test Loss: 1.7345 Acc: 0.3616\nEpoch 8/10 | Train Loss: 1.7300 Acc: 0.3614 | Test Loss: 1.7119 Acc: 0.3712\nEpoch 9/10 | Train Loss: 1.7237 Acc: 0.3671 | Test Loss: 1.7594 Acc: 0.3516\nEpoch 10/10 | Train Loss: 1.7049 Acc: 0.3711 | Test Loss: 1.6963 Acc: 0.3710\n\n Training RNN with hidden_size = 256\nEpoch 1/10 | Train Loss: 2.0748 Acc: 0.2306 | Test Loss: 2.0521 Acc: 0.2503\nEpoch 2/10 | Train Loss: 2.0544 Acc: 0.2393 | Test Loss: 2.0505 Acc: 0.2444\nEpoch 3/10 | Train Loss: 2.0495 Acc: 0.2409 | Test Loss: 1.9473 Acc: 0.2769\nEpoch 4/10 | Train Loss: 1.8676 Acc: 0.3122 | Test Loss: 1.7906 Acc: 0.3468\nEpoch 5/10 | Train Loss: 1.7495 Acc: 0.3584 | Test Loss: 1.7223 Acc: 0.3653\nEpoch 6/10 | Train Loss: 1.6936 Acc: 0.3812 | Test Loss: 1.6712 Acc: 0.3922\nEpoch 7/10 | Train Loss: 1.7244 Acc: 0.3679 | Test Loss: 1.6579 Acc: 0.3910\nEpoch 8/10 | Train Loss: 1.6609 Acc: 0.3904 | Test Loss: 1.6063 Acc: 0.4032\nEpoch 9/10 | Train Loss: 1.6284 Acc: 0.4044 | Test Loss: 1.6014 Acc: 0.4210\nEpoch 10/10 | Train Loss: 1.6123 Acc: 0.4131 | Test Loss: 1.6027 Acc: 0.4211\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model = OnlyOneRNN(input_size=96, hidden_size=512, num_classes=10).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(10):\n    train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n    test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n    print(f\"Epoch {epoch+1}/10 | \"\n            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n            f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T07:23:09.227213Z","iopub.execute_input":"2025-05-20T07:23:09.227468Z","iopub.status.idle":"2025-05-20T07:33:18.781667Z","shell.execute_reply.started":"2025-05-20T07:23:09.227451Z","shell.execute_reply":"2025-05-20T07:33:18.781056Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Train Loss: 2.1820 Acc: 0.1973 | Test Loss: 2.0618 Acc: 0.2293\nEpoch 2/10 | Train Loss: 2.1569 Acc: 0.1961 | Test Loss: 2.1094 Acc: 0.2221\nEpoch 3/10 | Train Loss: 2.1044 Acc: 0.2151 | Test Loss: 2.2211 Acc: 0.1620\nEpoch 4/10 | Train Loss: 2.0975 Acc: 0.2191 | Test Loss: 2.0544 Acc: 0.2378\nEpoch 5/10 | Train Loss: 2.1003 Acc: 0.2178 | Test Loss: 2.1692 Acc: 0.1721\nEpoch 6/10 | Train Loss: 2.1760 Acc: 0.1903 | Test Loss: 2.1180 Acc: 0.1988\nEpoch 7/10 | Train Loss: 2.1200 Acc: 0.2164 | Test Loss: 2.1374 Acc: 0.1947\nEpoch 8/10 | Train Loss: 2.1212 Acc: 0.2178 | Test Loss: 2.1793 Acc: 0.1685\nEpoch 9/10 | Train Loss: 2.1198 Acc: 0.2107 | Test Loss: 2.1848 Acc: 0.1980\nEpoch 10/10 | Train Loss: 2.1582 Acc: 0.2010 | Test Loss: 2.2018 Acc: 0.1963\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"#### Varying Number of Layers","metadata":{"execution":{"iopub.status.busy":"2025-05-20T09:57:32.020253Z","iopub.execute_input":"2025-05-20T09:57:32.021158Z","iopub.status.idle":"2025-05-20T09:57:32.026048Z","shell.execute_reply.started":"2025-05-20T09:57:32.021130Z","shell.execute_reply":"2025-05-20T09:57:32.025174Z"}}},{"cell_type":"markdown","source":"To examine how increasing the number of RNN layers (num_layers) affects the classification performance","metadata":{"execution":{"iopub.status.busy":"2025-05-20T09:57:55.266207Z","iopub.execute_input":"2025-05-20T09:57:55.266491Z","iopub.status.idle":"2025-05-20T09:57:55.272238Z","shell.execute_reply.started":"2025-05-20T09:57:55.266470Z","shell.execute_reply":"2025-05-20T09:57:55.271323Z"}}},{"cell_type":"code","source":"device = torch.device(\"cuda\")\n\nimport torch\nimport torch.nn as nn\n\nclass RNNRefined(nn.Module):\n    def __init__(self, input_size=96, hidden_size=256, num_layers=1, num_classes=10):\n        super().__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.i2h_layers = nn.ModuleList([\n            nn.Linear(input_size + hidden_size, hidden_size)\n        ])\n\n        for _ in range(1, num_layers):\n            self.i2h_layers.append(\n                nn.Linear(hidden_size + hidden_size, hidden_size)\n            )\n\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):  # x: [B, 3, 32, 32]\n        B = x.size(0)\n        x = x.permute(0, 2, 3, 1).reshape(B, 32, -1)\n\n        h = [torch.zeros(B, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n\n        for t in range(x.size(1)):\n            x_t = x[:, t, :]\n\n            for l in range(self.num_layers):\n                input_l = x_t if l == 0 else h[l - 1]\n                combined = torch.cat([input_l, h[l]], dim=1)\n                h[l] = torch.tanh(self.i2h_layers[l](combined))\n\n        return self.fc(h[-1])\n\n\n\nnum_layers = [1,2,3]\n\nfor num_layer in num_layers:\n    print(f\"Training RNN with num_layers = {num_layer}\")\n    model = RNNRefined(input_size=96, hidden_size=256, num_layers=num_layer, num_classes=10).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(10):\n        train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n        test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n    \n        print(f\"Epoch {epoch+1}/10 | \"\n                f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n                f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:47:21.611242Z","iopub.execute_input":"2025-05-20T08:47:21.611920Z","iopub.status.idle":"2025-05-20T09:23:01.949861Z","shell.execute_reply.started":"2025-05-20T08:47:21.611898Z","shell.execute_reply":"2025-05-20T09:23:01.949024Z"}},"outputs":[{"name":"stdout","text":"Training RNN with num_layers = 1\nEpoch 1/10 | Train Loss: 2.0763 Acc: 0.2259 | Test Loss: 2.0495 Acc: 0.2476\nEpoch 2/10 | Train Loss: 1.9754 Acc: 0.2686 | Test Loss: 1.9495 Acc: 0.2654\nEpoch 3/10 | Train Loss: 1.9134 Acc: 0.2965 | Test Loss: 2.0089 Acc: 0.2677\nEpoch 4/10 | Train Loss: 1.9250 Acc: 0.2893 | Test Loss: 1.8885 Acc: 0.3014\nEpoch 5/10 | Train Loss: 1.8230 Acc: 0.3205 | Test Loss: 1.8248 Acc: 0.3173\nEpoch 6/10 | Train Loss: 1.7724 Acc: 0.3410 | Test Loss: 1.8328 Acc: 0.3241\nEpoch 7/10 | Train Loss: 1.7608 Acc: 0.3477 | Test Loss: 1.7367 Acc: 0.3512\nEpoch 8/10 | Train Loss: 1.7528 Acc: 0.3491 | Test Loss: 1.7584 Acc: 0.3390\nEpoch 9/10 | Train Loss: 1.7764 Acc: 0.3466 | Test Loss: 1.6987 Acc: 0.3752\nEpoch 10/10 | Train Loss: 1.7650 Acc: 0.3495 | Test Loss: 1.7252 Acc: 0.3594\nTraining RNN with num_layers = 2\nEpoch 1/10 | Train Loss: 2.1620 Acc: 0.1999 | Test Loss: 2.0160 Acc: 0.2341\nEpoch 2/10 | Train Loss: 2.1350 Acc: 0.2096 | Test Loss: 2.0240 Acc: 0.2677\nEpoch 3/10 | Train Loss: 1.9421 Acc: 0.2863 | Test Loss: 1.8333 Acc: 0.3223\nEpoch 4/10 | Train Loss: 1.8116 Acc: 0.3373 | Test Loss: 1.8165 Acc: 0.3296\nEpoch 5/10 | Train Loss: 1.7704 Acc: 0.3487 | Test Loss: 1.7066 Acc: 0.3670\nEpoch 6/10 | Train Loss: 1.7378 Acc: 0.3629 | Test Loss: 1.7248 Acc: 0.3748\nEpoch 7/10 | Train Loss: 1.7546 Acc: 0.3551 | Test Loss: 1.7733 Acc: 0.3424\nEpoch 8/10 | Train Loss: 1.7381 Acc: 0.3575 | Test Loss: 1.7383 Acc: 0.3687\nEpoch 9/10 | Train Loss: 1.7955 Acc: 0.3368 | Test Loss: 1.7466 Acc: 0.3574\nEpoch 10/10 | Train Loss: 1.7588 Acc: 0.3527 | Test Loss: 1.6994 Acc: 0.3742\nTraining RNN with num_layers = 3\nEpoch 1/10 | Train Loss: 2.0724 Acc: 0.2325 | Test Loss: 1.9907 Acc: 0.2580\nEpoch 2/10 | Train Loss: 2.0066 Acc: 0.2528 | Test Loss: 1.9267 Acc: 0.2882\nEpoch 3/10 | Train Loss: 1.9801 Acc: 0.2662 | Test Loss: 2.0440 Acc: 0.2455\nEpoch 4/10 | Train Loss: 1.9988 Acc: 0.2671 | Test Loss: 2.1296 Acc: 0.2169\nEpoch 5/10 | Train Loss: 1.9880 Acc: 0.2656 | Test Loss: 1.8721 Acc: 0.3001\nEpoch 6/10 | Train Loss: 1.9807 Acc: 0.2687 | Test Loss: 2.1983 Acc: 0.1796\nEpoch 7/10 | Train Loss: 2.1077 Acc: 0.2120 | Test Loss: 2.0463 Acc: 0.2243\nEpoch 8/10 | Train Loss: 2.0975 Acc: 0.2174 | Test Loss: 2.0771 Acc: 0.2347\nEpoch 9/10 | Train Loss: 2.0710 Acc: 0.2271 | Test Loss: 2.0154 Acc: 0.2564\nEpoch 10/10 | Train Loss: 2.0197 Acc: 0.2484 | Test Loss: 2.2011 Acc: 0.1585\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"#### Trying the LSTM Model","metadata":{}},{"cell_type":"markdown","source":"LSTM (Long Short-Term Memory) is a type of Recurrent Neural Network (RNN) that was specifically designed to overcome the limitations of standard (vanilla) RNNs  especially when it comes to learning long-range dependencies in sequential data.\n\nUnlike vanilla RNNs, which often suffer from vanishing or exploding gradients, LSTM introduces gates (input, forget, and output) to control the flow of information, allowing the network to retain important context over time.\n\nIn this step, we keep the best setting from the previous RNN experiments:\n\n1. hidden_size = 256\n2. input_size = 96\n3. Try num_layers = 2\n4. No dropout (for now)\n\nThis will allow us to directly compare the impact of using LSTM instead of RNN under similar configurations.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nimport torch\nimport torch.nn as nn\n\nclass RNNwithLSTM(nn.Module):\n    def __init__(self, input_size=96, hidden_size=256, num_classes=10):\n        super().__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n        self.x2h = nn.Linear(input_size, 4 * hidden_size)\n        self.h2h = nn.Linear(hidden_size, 4 * hidden_size)\n\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        B = x.size(0)\n        x = x.permute(0, 2, 3, 1).reshape(B, 32, -1)\n\n        h_t = torch.zeros(B, self.hidden_size, device=x.device)\n        c_t = torch.zeros(B, self.hidden_size, device=x.device)\n\n        for t in range(x.size(1)):\n            x_t = x[:, t, :]\n\n            gates = self.x2h(x_t) + self.h2h(h_t)\n            i_gate, f_gate, o_gate, g_gate = gates.chunk(4, dim=1)\n\n            i_t = torch.sigmoid(i_gate)\n            f_t = torch.sigmoid(f_gate)\n            o_t = torch.sigmoid(o_gate)\n            g_t = torch.tanh(g_gate)\n\n            c_t = f_t * c_t + i_t * g_t\n            h_t = o_t * torch.tanh(c_t)\n\n        return self.fc(h_t)\n\n\ndevice = torch.device(\"cuda\")\n\nmodel = RNNwithLSTM().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nepochs = 10\nfor epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n    test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:10:31.019018Z","iopub.execute_input":"2025-05-20T10:10:31.019588Z","iopub.status.idle":"2025-05-20T10:22:04.839339Z","shell.execute_reply.started":"2025-05-20T10:10:31.019566Z","shell.execute_reply":"2025-05-20T10:22:04.838737Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Train Loss: 1.8032 Acc: 0.3348 | Test Loss: 1.6171 Acc: 0.4069\nEpoch 2/10 | Train Loss: 1.5357 Acc: 0.4403 | Test Loss: 1.4415 Acc: 0.4678\nEpoch 3/10 | Train Loss: 1.3768 Acc: 0.4991 | Test Loss: 1.3233 Acc: 0.5193\nEpoch 4/10 | Train Loss: 1.2558 Acc: 0.5470 | Test Loss: 1.2609 Acc: 0.5451\nEpoch 5/10 | Train Loss: 1.1470 Acc: 0.5888 | Test Loss: 1.1652 Acc: 0.5843\nEpoch 6/10 | Train Loss: 1.0530 Acc: 0.6232 | Test Loss: 1.1329 Acc: 0.5990\nEpoch 7/10 | Train Loss: 0.9703 Acc: 0.6524 | Test Loss: 1.1149 Acc: 0.6033\nEpoch 8/10 | Train Loss: 0.8854 Acc: 0.6844 | Test Loss: 1.1001 Acc: 0.6100\nEpoch 9/10 | Train Loss: 0.8062 Acc: 0.7136 | Test Loss: 1.0892 Acc: 0.6241\nEpoch 10/10 | Train Loss: 0.7277 Acc: 0.7419 | Test Loss: 1.1067 Acc: 0.6174\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Now, we see that we need dropout Layer to refine the result, and let's see how is the result when I try a different number of layers which is 3. And see how it works","metadata":{}},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_size=96, hidden_size=256, num_layers=3, dropout=0.3, num_classes=10):\n        super().__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        self.x2h = nn.ModuleList()\n        self.h2h = nn.ModuleList()\n        self.dropouts = nn.ModuleList()\n\n        for layer in range(num_layers):\n            in_size = input_size if layer == 0 else hidden_size\n            self.x2h.append(nn.Linear(in_size, 4 * hidden_size))\n            self.h2h.append(nn.Linear(hidden_size, 4 * hidden_size))\n            self.dropouts.append(nn.Dropout(dropout))\n\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):  # x: [B, 3, 32, 32]\n        B = x.size(0)\n        x = x.permute(0, 2, 3, 1).reshape(B, 32, -1)\n\n        h = [torch.zeros(B, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n        c = [torch.zeros(B, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n\n        for t in range(x.size(1)):\n            input_t = x[:, t, :]\n            for layer in range(self.num_layers):\n                gates = self.x2h[layer](input_t) + self.h2h[layer](h[layer])\n                i_gate, f_gate, o_gate, g_gate = gates.chunk(4, dim=1)\n\n                i = torch.sigmoid(i_gate)\n                f = torch.sigmoid(f_gate)\n                o = torch.sigmoid(o_gate)\n                g = torch.tanh(g_gate)\n\n                c[layer] = f * c[layer] + i * g\n                h[layer] = o * torch.tanh(c[layer])\n\n                input_t = self.dropouts[layer](h[layer])\n\n        return self.fc(h[-1])\n\n\ndevice = torch.device(\"cuda\")\n\nmodel = RNNModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nepochs = 10\nfor epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n    test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:31:17.287192Z","iopub.execute_input":"2025-05-20T10:31:17.287591Z","iopub.status.idle":"2025-05-20T10:43:14.810295Z","shell.execute_reply.started":"2025-05-20T10:31:17.287567Z","shell.execute_reply":"2025-05-20T10:43:14.809571Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Train Loss: 1.8265 Acc: 0.3212 | Test Loss: 1.6028 Acc: 0.4159\nEpoch 2/10 | Train Loss: 1.5764 Acc: 0.4175 | Test Loss: 1.4894 Acc: 0.4476\nEpoch 3/10 | Train Loss: 1.4282 Acc: 0.4790 | Test Loss: 1.3634 Acc: 0.5104\nEpoch 4/10 | Train Loss: 1.3032 Acc: 0.5280 | Test Loss: 1.2758 Acc: 0.5399\nEpoch 5/10 | Train Loss: 1.1891 Acc: 0.5732 | Test Loss: 1.1830 Acc: 0.5736\nEpoch 6/10 | Train Loss: 1.1005 Acc: 0.6059 | Test Loss: 1.1242 Acc: 0.5995\nEpoch 7/10 | Train Loss: 1.0186 Acc: 0.6330 | Test Loss: 1.1153 Acc: 0.6073\nEpoch 8/10 | Train Loss: 0.9404 Acc: 0.6620 | Test Loss: 1.0987 Acc: 0.6128\nEpoch 9/10 | Train Loss: 0.8679 Acc: 0.6882 | Test Loss: 1.0618 Acc: 0.6331\nEpoch 10/10 | Train Loss: 0.7983 Acc: 0.7165 | Test Loss: 1.0717 Acc: 0.6312\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_size=96, hidden_size=256, num_layers=4, dropout=0.4, num_classes=10):\n        super().__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        self.x2h = nn.ModuleList()\n        self.h2h = nn.ModuleList()\n        self.dropouts = nn.ModuleList()\n\n        for layer in range(num_layers):\n            in_size = input_size if layer == 0 else hidden_size\n            self.x2h.append(nn.Linear(in_size, 4 * hidden_size))\n            self.h2h.append(nn.Linear(hidden_size, 4 * hidden_size))\n            self.dropouts.append(nn.Dropout(dropout))\n\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):  # x: [B, 3, 32, 32]\n        B = x.size(0)\n        x = x.permute(0, 2, 3, 1).reshape(B, 32, -1)\n\n        h = [torch.zeros(B, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n        c = [torch.zeros(B, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n\n        for t in range(x.size(1)):\n            input_t = x[:, t, :]\n            for layer in range(self.num_layers):\n                gates = self.x2h[layer](input_t) + self.h2h[layer](h[layer])\n                i_gate, f_gate, o_gate, g_gate = gates.chunk(4, dim=1)\n\n                i = torch.sigmoid(i_gate)\n                f = torch.sigmoid(f_gate)\n                o = torch.sigmoid(o_gate)\n                g = torch.tanh(g_gate)\n\n                c[layer] = f * c[layer] + i * g\n                h[layer] = o * torch.tanh(c[layer])\n\n                input_t = self.dropouts[layer](h[layer])\n\n        return self.fc(h[-1])\n\n\ndevice = torch.device(\"cuda\")\n\nmodel = RNNModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nepochs = 10\nfor epoch in range(epochs):\n    train_loss, train_acc = train_one_epoch(model, cifar_train_loader, criterion, optimizer, device)\n    test_loss, test_acc = evaluate(model, cifar_test_loader, criterion, device)\n\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:52:07.629072Z","iopub.execute_input":"2025-05-20T11:52:07.629607Z","iopub.status.idle":"2025-05-20T12:15:28.339316Z","shell.execute_reply.started":"2025-05-20T11:52:07.629583Z","shell.execute_reply":"2025-05-20T12:15:28.338600Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Train Loss: 1.8382 Acc: 0.3185 | Test Loss: 1.6993 Acc: 0.3677\nEpoch 2/10 | Train Loss: 1.5735 Acc: 0.4199 | Test Loss: 1.4725 Acc: 0.4516\nEpoch 3/10 | Train Loss: 1.4331 Acc: 0.4756 | Test Loss: 1.3595 Acc: 0.5014\nEpoch 4/10 | Train Loss: 1.3176 Acc: 0.5267 | Test Loss: 1.2702 Acc: 0.5351\nEpoch 5/10 | Train Loss: 1.2158 Acc: 0.5630 | Test Loss: 1.1795 Acc: 0.5745\nEpoch 6/10 | Train Loss: 1.1299 Acc: 0.5964 | Test Loss: 1.1935 Acc: 0.5800\nEpoch 7/10 | Train Loss: 1.0574 Acc: 0.6223 | Test Loss: 1.1034 Acc: 0.6047\nEpoch 8/10 | Train Loss: 0.9932 Acc: 0.6450 | Test Loss: 1.0653 Acc: 0.6253\nEpoch 9/10 | Train Loss: 0.9250 Acc: 0.6675 | Test Loss: 1.0738 Acc: 0.6281\nEpoch 10/10 | Train Loss: 0.8754 Acc: 0.6888 | Test Loss: 1.0274 Acc: 0.6408\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"After tuning several hyperparameters including `hidden_size`, `num_layers`, and `dropout`, the best performing configuration was:\n\n- **Model**: LSTM\n- **Hidden Size**: 256\n- **Num Layers**: 4\n- **Dropout**: 0.4\n- **Epochs**: 10\n\n### Final Performance:\n- **Training Accuracy**: 68.88%\n- **Test Accuracy**: **64.08%**\n\nThis setup achieved the highest generalization performance across all experiments, confirming that LSTM with moderate depth and dropout provides the best balance between learning capacity and regularization.","metadata":{}},{"cell_type":"markdown","source":"## 4. Conclusion","metadata":{}},{"cell_type":"markdown","source":"After a series of experiments, we evaluated how different architectural choices affect the classification performance of RNN-based models (Vanila RNN and LSTM) on image data. Below are the key takeaways:\n\n1.\tEffect of Increasing Hidden Size:\nIncreasing the hidden_size from 64 to 256 significantly improved the models ability to learn richer representations:\n\n- hidden_size = 64: Model underfit with test accuracy around 33%\n- hidden_size = 256: Achieved the best performance (~42%) with Vanilla RNN\n- hidden_size = 512: Performance degraded drastically due to over-parameterization, leading to unstable training\n- \nConclusion: There is an optimal range of hidden size  beyond that, model complexity hurts performance without regularization.\n\n2.\tEffect of Increasing Number of RNN Layers:\nAdding more RNN layers showed diminishing returns in Vanilla RNN:\n- Num_layers = 1: Solid baseline\n- Num_layers = 2: Gets slight improvement\n- Num_layers = 3: Accuracy collapsed, indicating vanishing gradients or training instability\nConclusion: Deep vanilla RNNs are unstable without advanced mechanisms like LSTM.\n\n3.\tWhy LSTM Performs Better\nReplacing Vanilla RNN with LSTM led to:\n- Higher stability during training\n- Better generalization with no sudden performance drop\n- Gradual increase in test accuracy up to 61%\nThis is due to LSTM's internal gating mechanisms, which preserve long-term information and mitigate the vanishing gradient problem.\n\n4.\tFinal LSTM with 4 Layers & Dropout\nUnlike Vanilla RNN, the LSTM model benefited from a deeper architecture:\n- num_layers = 4 with dropout=0.4 achieved high training and testing performance\n- Overfitting was reduced, and test accuracy was maintained\nConclusion: LSTM supports deeper architectures and benefits from dropout regularization, making it more scalable and robust than Vanilla RNN.\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T11:16:30.793809Z","iopub.execute_input":"2025-05-20T11:16:30.794102Z","iopub.status.idle":"2025-05-20T11:16:30.801950Z","shell.execute_reply.started":"2025-05-20T11:16:30.794083Z","shell.execute_reply":"2025-05-20T11:16:30.800896Z"}}},{"cell_type":"markdown","source":"That will wrap up my code in this notebook, thank you for your attention.","metadata":{}}]}