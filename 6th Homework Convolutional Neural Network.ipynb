{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11528677,"sourceType":"datasetVersion","datasetId":7230817}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network on Cifar-10 Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Hello everyone and Prof Di Bo Ya. My name is Denzel Elden Wijaya, and in this notebook, I will demonstrate how to implement Convolutional Neural Network on Cifar-10 Datasets, while the previous one is utilizing the FFNN, or the fully connected Neural Network one, here we will be focusing more into the Convolutional Layers, and the effects of the all the hyperparameters on the performance of the CNN itself. I will extract the raw data and create a custom dataset class that inherits from `torch.utils.data.Dataset`. This custom dataset will then be passed to `torch.utils.data.DataLoader` to enable efficient data loading during training.","metadata":{}},{"cell_type":"markdown","source":"The process will include these steps:\n1. Load and Prepare the Dataset\n2. Build the initial CNN Model\n3. Tune the Model\n4. Conclusion","metadata":{}},{"cell_type":"markdown","source":"## 1. Load and Prepare the Dataset","metadata":{"execution":{"iopub.status.busy":"2025-04-23T13:12:25.302342Z","iopub.execute_input":"2025-04-23T13:12:25.302645Z","iopub.status.idle":"2025-04-23T13:12:25.306937Z","shell.execute_reply.started":"2025-04-23T13:12:25.302622Z","shell.execute_reply":"2025-04-23T13:12:25.305912Z"}}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass CifarDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_to_idx = {}\n\n        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n            class_path = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_path):\n                self.class_to_idx[class_name] = idx\n                for file_name in os.listdir(class_path):\n                    if file_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                        self.image_paths.append(os.path.join(class_path, file_name))\n                        self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        label = self.labels[index]\n        image = Image.open(image_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:16:37.210177Z","iopub.execute_input":"2025-04-24T01:16:37.210876Z","iopub.status.idle":"2025-04-24T01:16:47.876636Z","shell.execute_reply.started":"2025-04-24T01:16:37.210852Z","shell.execute_reply":"2025-04-24T01:16:47.875739Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar10/cifar10_train\", transform=transform)\ntest_dataset = CifarDataset(root_dir=\"/kaggle/input/cifar10/cifar10_test\", transform=transform)\n\ncifar_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ncifar_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\nprint(f\"Total Training Data: {len(train_dataset)}\")\nprint(f\"Total Testing Data: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:17:03.965695Z","iopub.execute_input":"2025-04-24T01:17:03.966353Z","iopub.status.idle":"2025-04-24T01:17:05.309775Z","shell.execute_reply.started":"2025-04-24T01:17:03.966328Z","shell.execute_reply":"2025-04-24T01:17:05.309122Z"}},"outputs":[{"name":"stdout","text":"Total Training Data: 50000\nTotal Testing Data: 10000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# let's check the first image and its label\n\nfrom IPython.display import display\n\nimage, label = train_dataset[1]\nimage = transforms.ToPILImage()(image)\ndisplay(image)\n\nclass_names = list(train_dataset.class_to_idx.keys())\nlabel_name = class_names[label]\n\nprint(f\"Label: {label_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:17:05.310873Z","iopub.execute_input":"2025-04-24T01:17:05.311130Z","iopub.status.idle":"2025-04-24T01:17:05.457548Z","shell.execute_reply.started":"2025-04-24T01:17:05.311109Z","shell.execute_reply":"2025-04-24T01:17:05.456896Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAEPklEQVR4AXWWS4scVRTHu6q6O20Y0cgkBCainQdINnESyPjCGfE1C3Et+iFEXGclgQgugn4BUSGQXcZNNkFwrYiLmCAqJlFQXGSGnu6uR1eVv3NP15nbtzo1za1zz/mf/3ncU1UT/fbnvY67oijyBd3WdY3SZASVUZpJBfVVvWiqqiorhNgMvgALNi5f6ctmMsECKyySrCRjCRDY0BBecbZKtMV46tX2RWNKBAkQeKIxRCBbPN9rKbimB1GH3/IWuXTD/iwl0pBmslzrTi0nQIvUZoggR9MjmGykbY3vjswhdOXWzI+Z2xo1oVeTZWouvgAmjqU3DJIECC6cHY/MAIJyKS+aYKu+j4wXnIHxGpF5mqCMwWrhm3jkQX4UEXXxDMx+GDOZAIXKGhIZQWWLqi3XqV7SIsP5bkrUJDgfMCga/oOugnHUVCCwMIBlyin1+32euPlxuUdPQ4Jh+OIkETA/x5flWTkrNYNGJ7V2lRFPJXLx6ySK8yz//rtbt2///MKLLz35xBGuJOkBY7rLcpZNp/vjUZZldZQUbLP05PDk8eNrsGkSrjjkTvT7vfukmSRJExxM1Et6X3395eVPLvHGOnToMBmtrDwOmiTImQBJ3F17ei1N0x9/+AnH4anh1c+/WF+/UFW0RTpDweBxlwqUHUFjsDICeZGurAz2R5M8S8k7z6arR49NJ+PRaLcqo4sXN765dr2K4m9v7JRFcf7C+VNnzhRF0TDwHMAuBzM/A2NXwRUYzwrS75NPmReDwWMbGxvUsbNz45WXt849v97r9cs6eu/9DyiLFmXp1CPRCgjgHbIdIDh8ppPs6OqxtRMndnf37vxy5+HDvbt3f33zrbe3XnvjyqefDQaHZ6V0YTza48bocuxS+nzo5yNEotIin1prBMxpPvPscHt7e388eefdzmQ8ee7s2c3NTb4iSbcPu3ShU8dJR46yuVyUyJ2EPi61tEhL01VTIAFm4+bNW2mWf/jRx69uvU5VeV7QB4ZBph834RVqTdE5ys5pnNGZoj/uP1BqherKqDz4+6///v3nqSOrw9On0zyvmbQ4TmJ6EXN48hKQhaENP00wuBHSvlQSQJ8AvwJA3V63m/SKGTOS8VJnsMgtkXZSANT8mkJEd9Al1OzQMP0s8wcNtF5WDTPHs+Y+GNArl960CcLoaGUWobP8UMsR1pW+RcIATSB6SQ/wxNF13LWbCO7PspEYxm6+VhCuC++iOZUBm8RdBEmcS29tJKQ+r22lleKmWepmccUSWG1rjCoEerboFyqAGZXhNFCgUS5MwNrIxdxkN68AyTyRA8+lGpTB1fYCIP9V2MUeue2msdXUBhheaw0ABy0ygwnm2daYSQUAj2rAvEWYDeHLbSLTGN40viAh5YFwH301+Gnql1LzgkhNxugj8VW9WVXDltcltvAMNJh8uZqqTVBTe10az2D/A38CY+KoLPzAAAAAAElFTkSuQmCC","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2AU6kAzXmzfGrRI9TuLBtK1RpIpGjXykRt+3qcbvY0yT0vFMccVyemePJNb01L/SvC+sXVs0nlBgYUOcZzgvnHPXpXW8lASMEjkelADhxzXLab8PNAsZPOntEvrhZmljmuY13R5OcDaBkc9811QpwoAZHEkMKRRIqRoAqoowFA6AChulSdqjfpQB//9k="},"metadata":{}},{"name":"stdout","text":"Label: airplane\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"data_iter = iter(cifar_train_loader)\nimages, labels = next(data_iter)\nfor i in range(10):\n    image = transforms.ToPILImage()(images[i])\n    display(image)\n    print(f\"Label: {class_names[labels[i]]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:17:05.464933Z","iopub.execute_input":"2025-04-24T01:17:05.465532Z","iopub.status.idle":"2025-04-24T01:17:06.101132Z","shell.execute_reply.started":"2025-04-24T01:17:05.465509Z","shell.execute_reply":"2025-04-24T01:17:06.100455Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1LxZrFzoWr6TfPfCDSl837bEVB3KF+Ujv1rnJPjj4bXyREHl3D5+duw59+tS/F0N/Z9szcwbJA4H3uSvTPFeOaN4d0u5u/IaOQB8tuJUkAe1bxpqSTMZVHFs9mHj+11vxVpTaNqBfS4QwvQBjLOMIMEdjXpA6V4PZ+E38N6hcw6fcRXMUyqxGwoytyF9vWvZ9EvDe6TBIzhpFXZIR/eHFTUgkk0VCTb1PDPFuoX2srFCs95cYkImLrmMDPT26CsKzga21S0ntp0kjR1WdrdclFzznihr7xCPFE+g2NtM1zcTsnkspQKQTgscYPFXtUsvHnhUy3F7pDz2zxgvJCRJGpPrgdu/FNTdtdxOGp1fifxFY28M17ZzT3NzIUhjBUg8biTyB0Fb/AIC1t4mS2u2CrdANGhOSnoW9M/4V4rcazdanE1gljJdM0iPvggbI55AGOK3fDFj4js9RiubHSdRaMXKs6PAwV8HjcT7UoyvG0htWd0f/2Q=="},"metadata":{}},{"name":"stdout","text":"Label: truck\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDi4LQdx0q3HZ5wMYBq5DbM2Ao5yO1PlEsZkwrokbFCWTgn1+lNySNlFsqmCOM/Lnd6imTmcDBmk4xj5ulWbmQRLkFX9fWo5JYbgqsZyxXOKakmJxaL1xbXr2Y+wTCG4DAq5GQPrWhBcS3FqttezqbmMYkHl7SPoe4J71JbuX27VA9RSyWs8kwfYnmYwrE8AelYy1ZcXYp31iY/3b2+5GX5SvUVjRxrHeK8Rzwenauo+zR3cSoyNJsHGWOPyrKexW1kZhyxGMdBmqiEnc//2Q=="},"metadata":{}},{"name":"stdout","text":"Label: frog\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD0S7u23tz3rOa5YtzTrpjvP1qkzfN1Gax+qnqcyJxO3rVmG6OQKzkOe/Wpo+Hxml9UFzo5HUPHlpJr8VrZyLNCrFZmAOQe2PWr0uvW8c5Rra/Yg7SVgyPw5q1dafbfaftH2eNXPVig3VTlm4IG44OPlByK9ZU5XdzyZVlJKzNew1GwIDGC/DYIG+3wB+tPF3a+YVhFxlcZMke3dWKl46w/eC54HvUsVw24CRW54A/rSjQkp8zI9qlsz//Z"},"metadata":{}},{"name":"stdout","text":"Label: ship\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDjdIgn2yzIjssY3yPjge5NWNQ8f3128Ok2cQhjDBZZPvO3TOPQVlReI7ix0y8soj8lyMNz0p2lKWsppvIRCu1Xl7tk5xXbd3smc1la7RzHiNSdSeUsz7mbLMcknPNUdP8AON2I4IY5nkBTY67hyOvtj1rtrm0s7jSr23u7fazMk0N2iEsnUEEZ5Xnn6VD4dsI9GuSbuIPJJzHKpyrL/s/5zWE6d5eTNoVLQ80bPgfRtI1e3udWuAXlsmWQ2jHKsmfmPqcDnFZWpwf2PqV3ED+4MmYvRlJ4qloeq2/hy5NxDcvIrYDxEY3DuOPUVLeyXfiO5+1SxmKziBW3twcEJknrW6lp5mTjrrsdFa2Ft4rjLWFyLLWI41EcRb93Nt7c9/8AGtOw8Pmz0RrjXlEBlDBbJfvCQcBwf4fpXD2kcdvKrxeZC6nIZHPB/GtvUPEWoXDxNczRyrjAcggk+/PWm1d3ehO2iP/Z"},"metadata":{}},{"name":"stdout","text":"Label: automobile\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwBLm1kkaZHsDbushCzwMdjD3ByMn+tL/Z91PO8VpJNIUfDo8ZXafr0P51avdSzehNOuc2qNkOBkvkA5x+PX2pVm83fIzhXJAC7iQBzk/XpW0Kk3pNJlTdOC/dt3Gv4Z1Bl3OAGYZxuGT9ea6nwxbHTLKHS5nBuPtpk2KcnYVHNcisU0km6VUOGyHWTJIznpV7R7r7NqtrM0MhuXlDhy3VSemPpSlZKzRMeeo+ZbafidhdeC0010bT7MXUZ3GRpXy3sB+X86yGsrAT7JbaW2cHkNnH616aY2D7kYL7dqS4tLe7TbcQpJ9RWd2tiXFPc8fOk6gs0En7mOG6LeVwcjGcAn3FaeiaVqV5NHbi3KJHIC0jADAUjHP4V11/4T+0vEIrsrDExZIivQ/Wr2kaJ/ZhZvPZi3UZOKOZvcqN4qyeh//9k="},"metadata":{}},{"name":"stdout","text":"Label: automobile\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwC7a6hrMV9M6a1MkWflRhwR7HpWvbeONYtJ1t54PtBIJ37SR+Yrcl8P6c1ttWxBlUnbliQP1riF8RW0Gnm0mSPzDIy4UY2fjXJKtKn5k0cLOd7SsbEvxJv5r6S2sdPgcqoaVmc/JnsR64FVrrx5qwgfbJbxykcJsORXF/Dy2c+LZ5BG11A0pSUEZwrE4Yj0GOvvXrlzolgxMosbcMO4jGTwa2jVFVpSVkmXxM28ks2N3rXj9v4Xm1WfX5POMH2CaQkMpJkJLNx6cY/Ou61LxN/okjafJazTK/3XlAHv361yVl45htLnUxfxIJLw4fyyMIQm0fX61hyNnSvcejNP4caVNptxqDTeW26GFlZOuHG7B/DFdrcu4icgDoRXM+H9Y0+OJ5hJEkbw26LvkH8MeD39a1ZtY02RGVryMZXqJRz+tQ4MUoOWp//Z"},"metadata":{}},{"name":"stdout","text":"Label: horse\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwcXd0SB9pm/7+Gt7XEutAvRaMvmDYHSR2Ykg89jg1iwQ/Z7q2NzB5iSAOI92NwPA5rufF6XurwwLaXCSoltG1zCcKYmwAAB17D1pNgcYNYmCkeUnPfc//AMVQdYmzkRoD3+Z+f/HqkfQLxNOe6K/NG+Hi/iC4+99KyqYGvaPJqcNvbjYbu2/1JY43p12/gen1Nb1tM7tDbXsLRXAcbd52hse/f0xXFqzIysjFWByCDyK7HTvGNvJCsOr2xcgY86MA5+qmk0nuNNrY07zT9bZiz2Elv/d2/dYduTwR+dcnruiy6bcNIoDQkjJXopPb2r0DTPG+mWsLQJcRzWrf8sbhSAPpnp+FOvdU0C/0bVRc3WnpF5Ilit7VvmdugBzzn5s+nFCVhH//2Q=="},"metadata":{}},{"name":"stdout","text":"Label: ship\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDFhutNGnsj2qi5aER7yAQCA3zfU5Gf90UyS7s1jlZIItzWyxqCmcPvyW+u3vWTdSJZRRy3IaKKUkJIyHaxHXBxioft9iQCLqHn/aFfQewpcz99/eef7SVvh/A3LXUrBYSklrE7xxBY2MXRtrZLevJX8qke+sngnVbODa0aIr7MFG2HJPfrk8egrM0/7Hdi6WNkaVYWlDJyTtHTGevpUVtcGfToWaMo7je/PHtgY9K5lCM6rhFvmT76GrbjFSaVi/4jvP7Q8I2ekpvaa3mMjRtjAAUgbfb1zXnUloLLyyW+eUFgpH3R2OfU19D2GjaS2r6hfC3Xc5VVZu2Bzj8aqXug6Xe6raT+RGIrYOX4+8flC/1NeM69KU5Sva7udypSUUjyXSra8mubhbRXihKBWm5BQZ5A9+cV0C2bKgAUgAAD/P4V6Vp2iabbW06pGGSSQuDnPBOf0OalGl6epw1vuU8g/wAq68LmFChF2TuzGrhp1Hqz/9k="},"metadata":{}},{"name":"stdout","text":"Label: deer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1e21W1uIGmguIpIlJDOjAqCOuTXJ6/wCOLGbSLiO3uAhkIRW7spGSa8sj02W2tZLeC+uFikOXjDHafwp1n4bmvXbF0Y44Uy7v0UU/b82kTJzZW1a5Nw00UEpZR8xx3wK5iRyFU5zgV2SRaTpF8ZlupLgwACYKpJG44/LmqPiKGO2vvNt44pGYKyBQcMp5B/Khwa1ZV77FW08W/wBm6k8t7Fut3TKqiBtre2apzeONUurlW+0FbUygFOB8ue+Knlsba5GWjB9Mikt9LtI3z5QFYwr8qsZRmuqOvfxpo8ORbCWTnOLe3CZ+prjDPeahrFxqFyXVZWLbD29PyrR8hFT5cCo8471M68pKw+dn/9k="},"metadata":{}},{"name":"stdout","text":"Label: automobile\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDDjtLua2NxHZTPCOrrGSKqFmJ2qnzDtivedNu7K3S30y38oKkAPljHC9M15d4+vbc67eabZxLZy3EKNHcxHG8q2WHt1AP4VxSw1le5jyzfU5Xzl2gkKxNILqNT90bh0wKqtNGBHsZmYKN5bu3f8K3rXwhrt3ob6zDaA2igt94BmUdwO4rlUZN2Rg6s7tLUs2fibNje6gZBal7RLSNhJucspGcDqOM1yF9dyXl0LmWXzHXgNzx9M1EFQxgdQDwKjkiAPyk8VpKq5LlZDqNqw9HZie3qa9W0/wCI1lYeD4LPDb44hHsGOwrydUIB3SHb0pyxRKuQxwTnJOcUqdX2d2hRly7H/9k="},"metadata":{}},{"name":"stdout","text":"Label: dog\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Check the shape of the images and labels\n\nprint(f\"Shape of images: {images.shape}\")\nprint(f\"Label batch: {labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:17:08.726815Z","iopub.execute_input":"2025-04-24T01:17:08.727360Z","iopub.status.idle":"2025-04-24T01:17:08.737949Z","shell.execute_reply.started":"2025-04-24T01:17:08.727334Z","shell.execute_reply":"2025-04-24T01:17:08.737218Z"}},"outputs":[{"name":"stdout","text":"Shape of images: torch.Size([64, 3, 32, 32])\nLabel batch: tensor([9, 6, 8, 1, 1, 7, 8, 4, 1, 5, 1, 3, 4, 5, 7, 4, 6, 7, 1, 7, 6, 9, 7, 5,\n        9, 3, 8, 6, 5, 0, 4, 3, 6, 6, 1, 5, 9, 9, 7, 4, 7, 6, 4, 4, 1, 5, 8, 2,\n        8, 7, 1, 4, 8, 2, 5, 7, 8, 6, 5, 7, 0, 7, 6, 4])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"This part does not have any significant difference from the one that we have built on the previous homework, and we have successfully loaded the CIFAR dataset and implemented a custom dataset class. After ensuring that the dataset is properly processed, we've verified that the images and labels are correctly associated and displayed. The dataset is now ready for training.","metadata":{}},{"cell_type":"markdown","source":"## 2. Build the Initial CNN Model","metadata":{}},{"cell_type":"markdown","source":"With the dataset that we have prepared, we will proceed on building the Neural Network with at least one Convolutional Layer inside. In this phase, we will build the basic one without applying advanced refinements and adjustments. This initial model will be the baseline for the training later. ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ConvOnlyCNN(nn.Module):\n    def __init__(self):\n        super(ConvOnlyCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(16 * 32 * 32, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = x.view(x.size(0), -1)          \n        x = torch.relu(self.fc1(x))     \n        return self.fc2(x)            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T17:05:35.450082Z","iopub.execute_input":"2025-04-23T17:05:35.450349Z","iopub.status.idle":"2025-04-23T17:05:35.457333Z","shell.execute_reply.started":"2025-04-23T17:05:35.450329Z","shell.execute_reply":"2025-04-23T17:05:35.456653Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef train(model, train_loader, criterion, optimizer, device, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # Metrics\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        acc = 100. * correct / total\n        avg_loss = running_loss / len(train_loader)\n        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Acc: {acc:.2f}%\")\n\ndef evaluate(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    acc = 100. * correct / total\n    print(f\"Test Accuracy: {acc:.2f}%\")\n    return acc\n\ndevice = torch.device('cuda')\nmodel = ConvOnlyCNN().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, device, epochs=10)\nevaluate(model, cifar_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T17:15:10.630638Z","iopub.execute_input":"2025-04-23T17:15:10.630910Z","iopub.status.idle":"2025-04-23T17:30:53.686726Z","shell.execute_reply.started":"2025-04-23T17:15:10.630893Z","shell.execute_reply":"2025-04-23T17:30:53.685957Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1.5062 - Acc: 47.00%\nEpoch [2/10] - Loss: 1.1902 - Acc: 58.30%\nEpoch [3/10] - Loss: 1.0679 - Acc: 62.54%\nEpoch [4/10] - Loss: 0.9720 - Acc: 66.05%\nEpoch [5/10] - Loss: 0.8929 - Acc: 68.63%\nEpoch [6/10] - Loss: 0.8309 - Acc: 70.85%\nEpoch [7/10] - Loss: 0.7591 - Acc: 73.43%\nEpoch [8/10] - Loss: 0.6885 - Acc: 75.83%\nEpoch [9/10] - Loss: 0.6359 - Acc: 77.84%\nEpoch [10/10] - Loss: 0.5676 - Acc: 80.40%\nTest Accuracy: 59.50%\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"59.5"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"From the results, we can see that even without any hyperparameter tuning, dropout layers, or deep architectures, our CNN with a single convolutional layer already achieves around 59% accuracy on the testing set. For comparison: In the previous assignment using a Fully-Connected Neural Network (FFNN), even with various refinements and tuning techniques, the best accuracy we achieved was only around 5658%.\n\nSo, why does CNN perform just as well  or even better  with fewer modifications?\nThe key lies in how CNN and FFNN process image data:\n\n**CNN (Convolutional Neural Network):**\n- Learns and captures spectral features like edges, textures, and shapes.\n- Preserves spatial structure of the image.\n- Uses local receptive fields and weight sharing for efficient pattern recognition.\n\n**FFNN (Fully Connected Neural Network):**\n- Treats the image as a flat vector (e.g., 32323  3072D vector).\n- Loses spatial relationships between pixels.","metadata":{}},{"cell_type":"markdown","source":"## 3. Tune the Model","metadata":{}},{"cell_type":"markdown","source":"To further improve model performance and explore the power of CNNs, here are some next steps we can try:\n- Add more convolutional layers to capture more complex spatial features.\n- Increase the number of neurons in fully connected layers to improve capacity.\n- Introduce Dropout layers to reduce overfitting and improve generalization.\n- Apply Batch Normalization to stabilize and accelerate training.\n- Train for more epochs to allow the model more time to converge.\n- Experiment with different learning rates to find the most optimal update speed.\n- Try different activation functions like LeakyReLU or ELU.\n- Use MaxPooling to gradually reduce spatial dimensions.\n\nAll of these enhancements aim to improve the model's ability to learn general features and perform better on unseen data  without overfitting.","metadata":{}},{"cell_type":"markdown","source":"### First Step","metadata":{}},{"cell_type":"markdown","source":"First of all, let's focus on the CNN Core Implementation:\n\n1. Add a second convolutional layer\n To ensure the model extract as much spatial fature as it could\n\n2. Add MaxPooling after each conv block\n To let the model study about the hierachy (edge -> texture -> shape)\n\n3. Add BatchNorm after conv layers\n To stabilize the training and make the model fast to converge","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass RefinedCNN(nn.Module):\n    def __init__(self):\n        super(RefinedCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)                                 \n\n        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\ndevice = torch.device('cuda')\nmodel = RefinedCNN().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, device, epochs=10)\nevaluate(model, cifar_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:45:44.284700Z","iopub.execute_input":"2025-04-23T15:45:44.285013Z","iopub.status.idle":"2025-04-23T15:55:30.007505Z","shell.execute_reply.started":"2025-04-23T15:45:44.284993Z","shell.execute_reply":"2025-04-23T15:55:30.006918Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1.3565 - Acc: 52.23%\nEpoch [2/10] - Loss: 0.9864 - Acc: 65.22%\nEpoch [3/10] - Loss: 0.8712 - Acc: 69.64%\nEpoch [4/10] - Loss: 0.7898 - Acc: 72.48%\nEpoch [5/10] - Loss: 0.7288 - Acc: 74.50%\nEpoch [6/10] - Loss: 0.6792 - Acc: 76.47%\nEpoch [7/10] - Loss: 0.6289 - Acc: 78.16%\nEpoch [8/10] - Loss: 0.5907 - Acc: 79.39%\nEpoch [9/10] - Loss: 0.5528 - Acc: 80.53%\nEpoch [10/10] - Loss: 0.5183 - Acc: 82.05%\nTest Accuracy: 70.63%\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"70.63"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"class RefinedCNN2(nn.Module):\n    def __init__(self):\n        super(RefinedCNN2, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool3 = nn.MaxPool2d(2)\n\n        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.bn1(self.conv1(x)))) \n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))   \n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))   \n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n        \ndevice = torch.device('cuda')\nmodel = RefinedCNN2().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain(model, cifar_train_loader, criterion, optimizer, device, epochs=10)\nevaluate(model, cifar_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T17:30:53.687969Z","iopub.execute_input":"2025-04-23T17:30:53.688218Z","iopub.status.idle":"2025-04-23T17:47:03.570703Z","shell.execute_reply.started":"2025-04-23T17:30:53.688200Z","shell.execute_reply":"2025-04-23T17:47:03.570090Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 1.2543 - Acc: 55.51%\nEpoch [2/10] - Loss: 0.8715 - Acc: 69.53%\nEpoch [3/10] - Loss: 0.7410 - Acc: 74.21%\nEpoch [4/10] - Loss: 0.6500 - Acc: 77.33%\nEpoch [5/10] - Loss: 0.5794 - Acc: 79.81%\nEpoch [6/10] - Loss: 0.5085 - Acc: 82.33%\nEpoch [7/10] - Loss: 0.4528 - Acc: 84.24%\nEpoch [8/10] - Loss: 0.3959 - Acc: 86.22%\nEpoch [9/10] - Loss: 0.3446 - Acc: 87.99%\nEpoch [10/10] - Loss: 0.3026 - Acc: 89.34%\nTest Accuracy: 73.48%\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"73.48"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"By enhancing the initial CNN model with a second convolutional layer, batch normalization, and max pooling, we observed a significant improvement in test accuracy, reaching approximately 73%  a noticeable increase from the earlier baseline of 58%.These enhancements contributed to better feature extraction, training stability, and generalization. In particular:\n\n1. Additional convolutional layers enabled the model to capture more abstract spatial features. Even when we increase it to 3 layers, the accuracy increases by ~3%.\n2. Batch Normalization improved training convergence by reducing internal covariate shift.\n3. Max Pooling helped downsample feature maps, reducing overfitting and computational cost.\n\nThis result confirms the effectiveness of building a deeper architecture with normalization and pooling in achieving better performance on image classification tasks.","metadata":{}},{"cell_type":"markdown","source":"### Second Step","metadata":{}},{"cell_type":"markdown","source":"After observing a significant gap between the training and testing accuracy, it is clear that the model is experiencing overfitting. To address this issue and evaluate its impact on generalization, we propose the following next steps:\n\n1. Add Dropout Layers (e.g., 0.30.5 before the fully connected layers)\n This helps reduce overfitting by preventing the model from relying too heavily on specific neurons during training.\n\n2. Adjust the Number of Training Epochs\n If the training loss is still decreasing steadily at the end of the current training cycle, increasing the number of epochs may allow the model to further improve without prematurely stopping learning.","metadata":{}},{"cell_type":"code","source":"class RefinedCNN3(nn.Module):\n    def __init__(self):\n        super(RefinedCNN3, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool3 = nn.MaxPool2d(2)\n\n        self.dropout = nn.Dropout(0.25)\n        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\ndevice = torch.device('cuda')\nmodel = RefinedCNN3().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:07:47.285940Z","iopub.execute_input":"2025-04-23T19:07:47.286784Z","iopub.status.idle":"2025-04-23T19:07:47.306692Z","shell.execute_reply.started":"2025-04-23T19:07:47.286757Z","shell.execute_reply":"2025-04-23T19:07:47.305964Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Epochs: 10\nprint(\"Training from scratch for 10 epochs...\")\nmodel_10 = RefinedCNN3().to(device)\noptimizer_10 = torch.optim.Adam(model_10.parameters(), lr=0.001)\ntrain(model_10, cifar_train_loader, criterion, optimizer_10, device, epochs=10)\nevaluate(model_10, cifar_test_loader, device)\n\n# Epochs: 15\nprint(\"\\nTraining from scratch for 15 epochs...\")\nmodel_15 = RefinedCNN3().to(device)\noptimizer_15 = torch.optim.Adam(model_15.parameters(), lr=0.001)\ntrain(model_15, cifar_train_loader, criterion, optimizer_15, device, epochs=15)\nevaluate(model_15, cifar_test_loader, device)\n\n# Epochs: 20\nprint(\"\\nTraining from scratch for 20 epochs...\")\nmodel_20 = RefinedCNN3().to(device)\noptimizer_20 = torch.optim.Adam(model_20.parameters(), lr=0.001)\ntrain(model_20, cifar_train_loader, criterion, optimizer_20, device, epochs=20)\nevaluate(model_20, cifar_test_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:07:56.523867Z","iopub.execute_input":"2025-04-23T19:07:56.524141Z","iopub.status.idle":"2025-04-23T20:13:09.908226Z","shell.execute_reply.started":"2025-04-23T19:07:56.524124Z","shell.execute_reply":"2025-04-23T20:13:09.907593Z"}},"outputs":[{"name":"stdout","text":"Training from scratch for 10 epochs...\nEpoch [1/10] - Loss: 1.3539 - Acc: 52.03%\nEpoch [2/10] - Loss: 0.9558 - Acc: 66.25%\nEpoch [3/10] - Loss: 0.8222 - Acc: 71.16%\nEpoch [4/10] - Loss: 0.7335 - Acc: 74.27%\nEpoch [5/10] - Loss: 0.6722 - Acc: 76.53%\nEpoch [6/10] - Loss: 0.6203 - Acc: 78.10%\nEpoch [7/10] - Loss: 0.5707 - Acc: 79.95%\nEpoch [8/10] - Loss: 0.5327 - Acc: 81.45%\nEpoch [9/10] - Loss: 0.4931 - Acc: 82.68%\nEpoch [10/10] - Loss: 0.4599 - Acc: 83.86%\nTest Accuracy: 76.66%\n\nTraining from scratch for 15 epochs...\nEpoch [1/15] - Loss: 1.3295 - Acc: 52.43%\nEpoch [2/15] - Loss: 0.9543 - Acc: 66.31%\nEpoch [3/15] - Loss: 0.8228 - Acc: 70.97%\nEpoch [4/15] - Loss: 0.7401 - Acc: 74.06%\nEpoch [5/15] - Loss: 0.6771 - Acc: 76.18%\nEpoch [6/15] - Loss: 0.6198 - Acc: 78.15%\nEpoch [7/15] - Loss: 0.5747 - Acc: 79.74%\nEpoch [8/15] - Loss: 0.5326 - Acc: 81.42%\nEpoch [9/15] - Loss: 0.4979 - Acc: 82.31%\nEpoch [10/15] - Loss: 0.4607 - Acc: 83.69%\nEpoch [11/15] - Loss: 0.4322 - Acc: 84.66%\nEpoch [12/15] - Loss: 0.4044 - Acc: 85.78%\nEpoch [13/15] - Loss: 0.3748 - Acc: 86.68%\nEpoch [14/15] - Loss: 0.3524 - Acc: 87.27%\nEpoch [15/15] - Loss: 0.3333 - Acc: 88.24%\nTest Accuracy: 77.01%\n\nTraining from scratch for 20 epochs...\nEpoch [1/20] - Loss: 1.3623 - Acc: 51.11%\nEpoch [2/20] - Loss: 0.9672 - Acc: 65.67%\nEpoch [3/20] - Loss: 0.8332 - Acc: 70.67%\nEpoch [4/20] - Loss: 0.7461 - Acc: 73.85%\nEpoch [5/20] - Loss: 0.6884 - Acc: 75.95%\nEpoch [6/20] - Loss: 0.6302 - Acc: 77.87%\nEpoch [7/20] - Loss: 0.5839 - Acc: 79.31%\nEpoch [8/20] - Loss: 0.5439 - Acc: 80.80%\nEpoch [9/20] - Loss: 0.5025 - Acc: 82.23%\nEpoch [10/20] - Loss: 0.4716 - Acc: 83.39%\nEpoch [11/20] - Loss: 0.4421 - Acc: 84.38%\nEpoch [12/20] - Loss: 0.4157 - Acc: 85.23%\nEpoch [13/20] - Loss: 0.3904 - Acc: 86.04%\nEpoch [14/20] - Loss: 0.3629 - Acc: 87.10%\nEpoch [15/20] - Loss: 0.3435 - Acc: 87.82%\nEpoch [16/20] - Loss: 0.3185 - Acc: 88.63%\nEpoch [17/20] - Loss: 0.3062 - Acc: 89.25%\nEpoch [18/20] - Loss: 0.2915 - Acc: 89.54%\nEpoch [19/20] - Loss: 0.2727 - Acc: 90.27%\nEpoch [20/20] - Loss: 0.2594 - Acc: 90.77%\nTest Accuracy: 78.94%\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"78.94"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"**Dropout Rate Experiments**\n\nInitially, we tried adding dropout after every convolutional block with increasing rates (e.g., 0.3, 0.35, 0.4). However, this caused a dramatic drop in performance  the test accuracy fell to 55%, as the model lost critical information during feature extraction. We then refined our approach by applying a single dropout layer before the fully connected layer, which yielded much better results:\n\na. Dropout rate = 0.5: Accuracy dropped to 70%, indicating the regularization was too strong.\nb. Dropout rate = 0.25: Achieved the best result of 76%, outperforming the previous baseline of 73%.\n\nThis highlights that dropout should be applied carefully and at the right place. Applying too many dropout layers or using a high rate can disrupt learning, especially in convolutional networks where spatial features are sensitive.\n\n**Epoch Tuning Results**\n\nWe also trained the same model from scratch using different epoch values:\n\t10 epochs: 76.66%\n\t15 epochs: Reached 77.01%\n\t20 epochs: Reached 78.94%\n\t25 epochs: did not reach 80% and start to plateau\nThese results suggest that extending training beyond 20 epochs does not bring significant improvements once the model has already converged. Its more efficient to stop training when the loss no longer decreases meaningfully between epochs.","metadata":{}},{"cell_type":"markdown","source":"### Third Step","metadata":{}},{"cell_type":"markdown","source":"To further improve training stability and optimize performance, we now focus on adjusting hyperparameters and the learning behavior of the model:\n\n1. Experiment with Different Learning Rates (e.g., 0.0005 or 0.005)\n Finding the right learning rate is crucial  too high may cause divergence, while too low can slow down convergence or get stuck in suboptimal results.\n\n2. Varying number of neurons (64, 128, 256)\n To find out which one can give a higher and lower accuracy when being examined. Since number or neurons can not be set statically as it will vary based on the dataset.\n\n3. Batch Size Experimentation\n Smaller batch sizes may generalize better but result in noisier updates, while larger batches offer more stable gradients but might overfit.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNNModel(nn.Module):\n    def __init__(self, fc_neurons=128, dropout_rate=0.25):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool3 = nn.MaxPool2d(2)\n\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc1 = nn.Linear(128 * 4 * 4, fc_neurons)\n        self.fc2 = nn.Linear(fc_neurons, 10)\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:20:58.203567Z","iopub.execute_input":"2025-04-24T01:20:58.204084Z","iopub.status.idle":"2025-04-24T01:20:58.213306Z","shell.execute_reply.started":"2025-04-24T01:20:58.204058Z","shell.execute_reply":"2025-04-24T01:20:58.212318Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"## Learning Rate Experiments\n\nlearning_rates = [0.0005, 0.001, 0.005]\nfor lr in learning_rates:\n    print(f\"\\nTraining CNNModel with learning rate = {lr}\")\n    model = CNNModel(fc_neurons=128, dropout_rate=0.25).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    train(model, cifar_train_loader, criterion, optimizer, device, epochs=20)\n    evaluate(model, cifar_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:37:31.264804Z","iopub.execute_input":"2025-04-23T20:37:31.265405Z","iopub.status.idle":"2025-04-23T21:58:20.448310Z","shell.execute_reply.started":"2025-04-23T20:37:31.265377Z","shell.execute_reply":"2025-04-23T21:58:20.447473Z"}},"outputs":[{"name":"stdout","text":"\nTraining CNNModel with learning rate = 0.0005\nEpoch [1/20] - Loss: 1.3847 - Acc: 50.23%\nEpoch [2/20] - Loss: 0.9981 - Acc: 65.00%\nEpoch [3/20] - Loss: 0.8645 - Acc: 69.73%\nEpoch [4/20] - Loss: 0.7817 - Acc: 72.73%\nEpoch [5/20] - Loss: 0.7230 - Acc: 74.75%\nEpoch [6/20] - Loss: 0.6671 - Acc: 76.68%\nEpoch [7/20] - Loss: 0.6218 - Acc: 78.28%\nEpoch [8/20] - Loss: 0.5889 - Acc: 79.36%\nEpoch [9/20] - Loss: 0.5529 - Acc: 80.38%\nEpoch [10/20] - Loss: 0.5254 - Acc: 81.28%\nEpoch [11/20] - Loss: 0.4964 - Acc: 82.36%\nEpoch [12/20] - Loss: 0.4673 - Acc: 83.51%\nEpoch [13/20] - Loss: 0.4432 - Acc: 84.30%\nEpoch [14/20] - Loss: 0.4191 - Acc: 85.17%\nEpoch [15/20] - Loss: 0.4012 - Acc: 85.71%\nEpoch [16/20] - Loss: 0.3780 - Acc: 86.58%\nEpoch [17/20] - Loss: 0.3647 - Acc: 87.08%\nEpoch [18/20] - Loss: 0.3389 - Acc: 87.82%\nEpoch [19/20] - Loss: 0.3246 - Acc: 88.29%\nEpoch [20/20] - Loss: 0.3132 - Acc: 88.80%\nTest Accuracy: 78.66%\n\nTraining CNNModel with learning rate = 0.001\nEpoch [1/20] - Loss: 1.3210 - Acc: 52.44%\nEpoch [2/20] - Loss: 0.9378 - Acc: 66.82%\nEpoch [3/20] - Loss: 0.8060 - Acc: 71.88%\nEpoch [4/20] - Loss: 0.7281 - Acc: 74.59%\nEpoch [5/20] - Loss: 0.6676 - Acc: 76.59%\nEpoch [6/20] - Loss: 0.6138 - Acc: 78.43%\nEpoch [7/20] - Loss: 0.5644 - Acc: 80.04%\nEpoch [8/20] - Loss: 0.5258 - Acc: 81.50%\nEpoch [9/20] - Loss: 0.4937 - Acc: 82.61%\nEpoch [10/20] - Loss: 0.4560 - Acc: 84.06%\nEpoch [11/20] - Loss: 0.4270 - Acc: 84.96%\nEpoch [12/20] - Loss: 0.4071 - Acc: 85.50%\nEpoch [13/20] - Loss: 0.3750 - Acc: 86.65%\nEpoch [14/20] - Loss: 0.3527 - Acc: 87.31%\nEpoch [15/20] - Loss: 0.3368 - Acc: 88.19%\nEpoch [16/20] - Loss: 0.3114 - Acc: 88.96%\nEpoch [17/20] - Loss: 0.2949 - Acc: 89.42%\nEpoch [18/20] - Loss: 0.2773 - Acc: 89.99%\nEpoch [19/20] - Loss: 0.2677 - Acc: 90.34%\nEpoch [20/20] - Loss: 0.2525 - Acc: 90.96%\nTest Accuracy: 79.19%\n\nTraining CNNModel with learning rate = 0.005\nEpoch [1/20] - Loss: 1.7367 - Acc: 38.33%\nEpoch [2/20] - Loss: 1.1376 - Acc: 58.70%\nEpoch [3/20] - Loss: 0.9737 - Acc: 64.89%\nEpoch [4/20] - Loss: 0.8627 - Acc: 69.33%\nEpoch [5/20] - Loss: 0.7912 - Acc: 71.97%\nEpoch [6/20] - Loss: 0.7340 - Acc: 74.14%\nEpoch [7/20] - Loss: 0.6760 - Acc: 76.13%\nEpoch [8/20] - Loss: 0.6322 - Acc: 77.56%\nEpoch [9/20] - Loss: 0.5955 - Acc: 78.66%\nEpoch [10/20] - Loss: 0.5700 - Acc: 79.67%\nEpoch [11/20] - Loss: 0.5411 - Acc: 80.89%\nEpoch [12/20] - Loss: 0.5153 - Acc: 81.70%\nEpoch [13/20] - Loss: 0.4860 - Acc: 82.60%\nEpoch [14/20] - Loss: 0.4619 - Acc: 83.53%\nEpoch [15/20] - Loss: 0.4496 - Acc: 84.02%\nEpoch [16/20] - Loss: 0.4273 - Acc: 84.78%\nEpoch [17/20] - Loss: 0.4062 - Acc: 85.40%\nEpoch [18/20] - Loss: 0.3941 - Acc: 85.98%\nEpoch [19/20] - Loss: 0.3758 - Acc: 86.55%\nEpoch [20/20] - Loss: 0.3696 - Acc: 86.73%\nTest Accuracy: 74.73%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"You can see that when the learning rate is too aggressive  as in the case of lr = 0.005  the model's performance on the test set decreases significantly (accuracy drops to 74%). This happens because a high learning rate causes the model to overshoot optimal weights, leading to unstable training and poor generalization.\n\nOn the other hand, a very low learning rate like lr = 0.0005 results in slower convergence, and although it still achieves decent performance (78%), it is not optimal in terms of both training efficiency and final accuracy.\n\nTherefore, a learning rate of 0.001 strikes the best balance between convergence speed and stability, achieving the highest accuracy of 79.19%. This value is thus considered the best choice for our model and dataset.","metadata":{}},{"cell_type":"code","source":"## Neuron Size Tuning\n\nfc_sizes = [64, 128, 256]\nfor size in fc_sizes:\n    print(f\"\\nTraining CNNModel with FC neurons = {size}\")\n    model = CNNModel(fc_neurons=size, dropout_rate=0.25).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train(model, cifar_train_loader, criterion, optimizer, device, epochs=20)\n    evaluate(model, cifar_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:21:01.742765Z","iopub.execute_input":"2025-04-24T01:21:01.743023Z","iopub.status.idle":"2025-04-24T02:53:43.431959Z","shell.execute_reply.started":"2025-04-24T01:21:01.743003Z","shell.execute_reply":"2025-04-24T02:53:43.431281Z"}},"outputs":[{"name":"stdout","text":"\nTraining CNNModel with FC neurons = 64\nEpoch [1/20] - Loss: 1.3534 - Acc: 51.45%\nEpoch [2/20] - Loss: 0.9533 - Acc: 66.35%\nEpoch [3/20] - Loss: 0.8185 - Acc: 71.33%\nEpoch [4/20] - Loss: 0.7428 - Acc: 74.02%\nEpoch [5/20] - Loss: 0.6821 - Acc: 76.14%\nEpoch [6/20] - Loss: 0.6264 - Acc: 78.22%\nEpoch [7/20] - Loss: 0.5845 - Acc: 79.57%\nEpoch [8/20] - Loss: 0.5452 - Acc: 80.83%\nEpoch [9/20] - Loss: 0.5067 - Acc: 82.27%\nEpoch [10/20] - Loss: 0.4737 - Acc: 83.27%\nEpoch [11/20] - Loss: 0.4433 - Acc: 84.39%\nEpoch [12/20] - Loss: 0.4169 - Acc: 85.30%\nEpoch [13/20] - Loss: 0.3913 - Acc: 86.18%\nEpoch [14/20] - Loss: 0.3743 - Acc: 86.56%\nEpoch [15/20] - Loss: 0.3526 - Acc: 87.51%\nEpoch [16/20] - Loss: 0.3270 - Acc: 88.54%\nEpoch [17/20] - Loss: 0.3088 - Acc: 88.99%\nEpoch [18/20] - Loss: 0.2946 - Acc: 89.58%\nEpoch [19/20] - Loss: 0.2793 - Acc: 90.04%\nEpoch [20/20] - Loss: 0.2718 - Acc: 90.38%\nTest Accuracy: 79.21%\n\nTraining CNNModel with FC neurons = 128\nEpoch [1/20] - Loss: 1.3721 - Acc: 50.36%\nEpoch [2/20] - Loss: 0.9722 - Acc: 65.54%\nEpoch [3/20] - Loss: 0.8312 - Acc: 70.78%\nEpoch [4/20] - Loss: 0.7450 - Acc: 73.88%\nEpoch [5/20] - Loss: 0.6841 - Acc: 76.12%\nEpoch [6/20] - Loss: 0.6306 - Acc: 78.05%\nEpoch [7/20] - Loss: 0.5827 - Acc: 79.42%\nEpoch [8/20] - Loss: 0.5416 - Acc: 81.05%\nEpoch [9/20] - Loss: 0.5036 - Acc: 82.21%\nEpoch [10/20] - Loss: 0.4703 - Acc: 83.47%\nEpoch [11/20] - Loss: 0.4471 - Acc: 84.32%\nEpoch [12/20] - Loss: 0.4133 - Acc: 85.49%\nEpoch [13/20] - Loss: 0.3872 - Acc: 86.41%\nEpoch [14/20] - Loss: 0.3614 - Acc: 87.28%\nEpoch [15/20] - Loss: 0.3403 - Acc: 87.91%\nEpoch [16/20] - Loss: 0.3189 - Acc: 88.71%\nEpoch [17/20] - Loss: 0.3063 - Acc: 89.04%\nEpoch [18/20] - Loss: 0.2871 - Acc: 89.78%\nEpoch [19/20] - Loss: 0.2681 - Acc: 90.52%\nEpoch [20/20] - Loss: 0.2565 - Acc: 90.92%\nTest Accuracy: 76.89%\n\nTraining CNNModel with FC neurons = 256\nEpoch [1/20] - Loss: 1.3253 - Acc: 52.88%\nEpoch [2/20] - Loss: 0.9361 - Acc: 66.80%\nEpoch [3/20] - Loss: 0.8079 - Acc: 71.59%\nEpoch [4/20] - Loss: 0.7229 - Acc: 74.47%\nEpoch [5/20] - Loss: 0.6621 - Acc: 76.60%\nEpoch [6/20] - Loss: 0.6021 - Acc: 78.85%\nEpoch [7/20] - Loss: 0.5528 - Acc: 80.71%\nEpoch [8/20] - Loss: 0.5184 - Acc: 81.71%\nEpoch [9/20] - Loss: 0.4776 - Acc: 83.09%\nEpoch [10/20] - Loss: 0.4362 - Acc: 84.56%\nEpoch [11/20] - Loss: 0.4099 - Acc: 85.28%\nEpoch [12/20] - Loss: 0.3800 - Acc: 86.58%\nEpoch [13/20] - Loss: 0.3516 - Acc: 87.40%\nEpoch [14/20] - Loss: 0.3310 - Acc: 88.11%\nEpoch [15/20] - Loss: 0.3065 - Acc: 89.05%\nEpoch [16/20] - Loss: 0.2907 - Acc: 89.52%\nEpoch [17/20] - Loss: 0.2695 - Acc: 90.33%\nEpoch [18/20] - Loss: 0.2568 - Acc: 90.83%\nEpoch [19/20] - Loss: 0.2364 - Acc: 91.67%\nEpoch [20/20] - Loss: 0.2245 - Acc: 91.85%\nTest Accuracy: 76.31%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"## Batch Size Tuning\n\nbatch_sizes = [32, 64, 128]\nfor bs in batch_sizes:\n    print(f\"\\nTraining CNNModel with batch size = {bs}\")\n    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n\n    model = CNNModel(fc_neurons=128, dropout_rate=0.25).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train(model, train_loader, criterion, optimizer, device, epochs=20)\n    evaluate(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T03:20:44.277312Z","iopub.execute_input":"2025-04-24T03:20:44.277876Z","iopub.status.idle":"2025-04-24T04:43:32.818127Z","shell.execute_reply.started":"2025-04-24T03:20:44.277851Z","shell.execute_reply":"2025-04-24T04:43:32.817334Z"}},"outputs":[{"name":"stdout","text":"\nTraining CNNModel with batch size = 32\nEpoch [1/20] - Loss: 1.3048 - Acc: 53.36%\nEpoch [2/20] - Loss: 0.9367 - Acc: 66.93%\nEpoch [3/20] - Loss: 0.8101 - Acc: 71.62%\nEpoch [4/20] - Loss: 0.7252 - Acc: 74.70%\nEpoch [5/20] - Loss: 0.6626 - Acc: 76.87%\nEpoch [6/20] - Loss: 0.6085 - Acc: 78.65%\nEpoch [7/20] - Loss: 0.5588 - Acc: 80.49%\nEpoch [8/20] - Loss: 0.5173 - Acc: 81.90%\nEpoch [9/20] - Loss: 0.4771 - Acc: 83.26%\nEpoch [10/20] - Loss: 0.4421 - Acc: 84.61%\nEpoch [11/20] - Loss: 0.4101 - Acc: 85.54%\nEpoch [12/20] - Loss: 0.3834 - Acc: 86.49%\nEpoch [13/20] - Loss: 0.3616 - Acc: 87.22%\nEpoch [14/20] - Loss: 0.3399 - Acc: 87.90%\nEpoch [15/20] - Loss: 0.3138 - Acc: 88.89%\nEpoch [16/20] - Loss: 0.3007 - Acc: 89.26%\nEpoch [17/20] - Loss: 0.2835 - Acc: 89.99%\nEpoch [18/20] - Loss: 0.2682 - Acc: 90.48%\nEpoch [19/20] - Loss: 0.2536 - Acc: 90.97%\nEpoch [20/20] - Loss: 0.2451 - Acc: 91.25%\nTest Accuracy: 79.27%\n\nTraining CNNModel with batch size = 64\nEpoch [1/20] - Loss: 1.3519 - Acc: 51.64%\nEpoch [2/20] - Loss: 0.9569 - Acc: 66.12%\nEpoch [3/20] - Loss: 0.8226 - Acc: 71.04%\nEpoch [4/20] - Loss: 0.7390 - Acc: 73.83%\nEpoch [5/20] - Loss: 0.6748 - Acc: 76.31%\nEpoch [6/20] - Loss: 0.6229 - Acc: 78.12%\nEpoch [7/20] - Loss: 0.5785 - Acc: 79.68%\nEpoch [8/20] - Loss: 0.5401 - Acc: 81.15%\nEpoch [9/20] - Loss: 0.5039 - Acc: 82.31%\nEpoch [10/20] - Loss: 0.4671 - Acc: 83.53%\nEpoch [11/20] - Loss: 0.4362 - Acc: 84.73%\nEpoch [12/20] - Loss: 0.4103 - Acc: 85.49%\nEpoch [13/20] - Loss: 0.3868 - Acc: 86.47%\nEpoch [14/20] - Loss: 0.3619 - Acc: 87.27%\nEpoch [15/20] - Loss: 0.3387 - Acc: 88.01%\nEpoch [16/20] - Loss: 0.3196 - Acc: 88.68%\nEpoch [17/20] - Loss: 0.3077 - Acc: 89.12%\nEpoch [18/20] - Loss: 0.2841 - Acc: 89.87%\nEpoch [19/20] - Loss: 0.2730 - Acc: 90.18%\nEpoch [20/20] - Loss: 0.2591 - Acc: 90.67%\nTest Accuracy: 79.17%\n\nTraining CNNModel with batch size = 128\nEpoch [1/20] - Loss: 1.4106 - Acc: 49.39%\nEpoch [2/20] - Loss: 0.9991 - Acc: 64.72%\nEpoch [3/20] - Loss: 0.8475 - Acc: 70.43%\nEpoch [4/20] - Loss: 0.7643 - Acc: 73.21%\nEpoch [5/20] - Loss: 0.7011 - Acc: 75.51%\nEpoch [6/20] - Loss: 0.6490 - Acc: 77.28%\nEpoch [7/20] - Loss: 0.6050 - Acc: 78.79%\nEpoch [8/20] - Loss: 0.5773 - Acc: 79.76%\nEpoch [9/20] - Loss: 0.5385 - Acc: 81.06%\nEpoch [10/20] - Loss: 0.5117 - Acc: 82.04%\nEpoch [11/20] - Loss: 0.4767 - Acc: 83.19%\nEpoch [12/20] - Loss: 0.4520 - Acc: 84.09%\nEpoch [13/20] - Loss: 0.4307 - Acc: 84.74%\nEpoch [14/20] - Loss: 0.4038 - Acc: 85.69%\nEpoch [15/20] - Loss: 0.3881 - Acc: 86.24%\nEpoch [16/20] - Loss: 0.3615 - Acc: 87.22%\nEpoch [17/20] - Loss: 0.3457 - Acc: 87.86%\nEpoch [18/20] - Loss: 0.3236 - Acc: 88.54%\nEpoch [19/20] - Loss: 0.3125 - Acc: 89.05%\nEpoch [20/20] - Loss: 0.2928 - Acc: 89.64%\nTest Accuracy: 78.37%\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Analysis:\n- Batch size = 32 resulted in the best test accuracy (79.27%), likely due to noisier updates that help the model generalize better and avoid overfitting.\n- Batch size = 64 also performed well and remained stable, offering a good balance between training speed and accuracy.\n- Batch size = 128, while computationally faster, led to a slight drop in performance. This is likely because larger batches provide smoother gradients, which can reduce the regularizing effect of gradient noise and make the model prone to overfitting.\n\nConclusion:\nSmaller batch sizes such as 32 tend to offer better generalization at the cost of longer training time per epoch. For this model and dataset, a batch size of 32 is the most effective in terms of test performance, confirming the trade-off between stability and generalization that batch size introduces.","metadata":{}},{"cell_type":"markdown","source":"## 4. Conclusion","metadata":{}},{"cell_type":"markdown","source":"Throughout this project, we progressively enhanced our CNN model through architectural improvements and training optimizations. Each tuning component served a unique purpose in improving the models performance, generalization, and training stability.\n1. Convolutional Layers\n\n    Adding more convolutional layers allowed the model to learn hierarchical representations of features  from simple edges to complex textures and shapes. This deeper feature extraction significantly improved test accuracy compared to a shallow model. (59% -> 70%)\n\n2. Batch Normalization & Max Pooling\n\n    Batch normalization helped stabilize and accelerate training by normalizing activations, while max pooling allowed the model to downsample feature maps hierarchically, reducing overfitting and capturing essential patterns. Together, they created a strong backbone for image understanding.\n\n3. Dropout Layers\n\n    Dropout was effective in reducing overfitting, particularly when placed before the fully connected layer. However, excessive dropout or applying it too early (e.g., after every convolution) disrupted feature learning. A moderate dropout rate (e.g., 0.25) applied at the right position proved to be the most effective.\n\n4. Number of Epochs\n    \n    Increasing the number of epochs gave the model more time to learn meaningful patterns. However, after a certain point (e.g., beyond 20 epochs), improvements in accuracy plateaued, making further training inefficient. Thus, more epochs do not always mean better performance.\n\n5. Learning Rate\n\n    The learning rate significantly impacted the convergence behavior. A well-balanced rate like 0.001 achieved the best results. Too low (0.0005) led to slow learning, while too high (0.005) caused unstable training or divergence.\n\n6. Number of Neurons\n\n    The number of neurons in the fully connected layer determined the capacity of the final classifier. Interestingly, a size of 64 neurons provided the best generalization, achieving the highest test accuracy. While 128 neurons offered a balanced performance, increasing to 256 neurons led to overfitting, with higher training accuracy but no improvement  and even a slight drop  in test performance. But 32 neurons will give you an underfitting result, hence fo this dataset, 64 neuron is the best number.\n\n8. Batch Size\n\n    Batch size influenced the stability and generalization of the model. A batch size of 32 produced slightly better results due to noisier updates (which help avoid local minima), while larger sizes like 128 were more stable but sometimes overfit slightly\n","metadata":{}},{"cell_type":"markdown","source":"That will be the end of this notebook, hope you gains insight from it. Thank You for giving attention until the end.","metadata":{}}]}